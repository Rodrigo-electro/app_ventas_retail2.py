# -*- coding: utf-8 -*-
"""app_ventas_retail.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LYLfZVk1Xu3kThMZZWztutU2ZrEJdYn7

# Clase 4 modulo GMR

# 1 Implementaci√≥n y comunicaci√≥n de resultados ML

## 1.1 Contexto del proyecto integrado

**Escenario:** Eres analista de datos en ‚ÄúRetailMax‚Äù, una cadena de tiendas que quiere implementar un sistema de predicci√≥n de ventas para optimizar inventario y estrategias comerciales. A lo largo de estos ejercicios, construir√°s un sistema completo desde la automatizaci√≥n del modelo hasta la comunicaci√≥n ejecutiva.

## 1.2 Creaci√≥n de Pipeline ML automatizado en Google Colab

**Objetivo:** Desarrollar un pipeline reproducible para el modelo de predicci√≥n de ventas

### 1.2.1 Contexto
RetailMax necesita que el modelo de predicci√≥n de ventas sea reproducible y pueda ejecutarse autom√°ticamente cada semana con nuevos datos.

### 1.2.2 Instrucciones Paso a Paso

### Paso 0: Creaci√≥n de dataset
"""

# Celda ejecutable apra generar el dataset en la carpeta /content/
import pandas as pd
import numpy as np
import os

# asegurar que exista la carpeta /content
os.makedirs('content', exist_ok=True)

# reproducibilidad
np.random.seed(42)

#parametros generales
n_tiendas = 50
semanas = 104 # 2 a√±os
fechas = pd.date_range(start="2022-01-03", periods=semanas, freq="W-MON")
tiendas = range (1, n_tiendas + 1)
data = []

for tienda_id in tiendas:
    base_ventas = np.random.normal(15000, 3000)
    for fecha in fechas:

        promocion = np.random.choice([0, 1], p=[0.7, 0.3])
        inventario = np.random.normal(50000, 10000)
        temperatura = np.random.normal(20, 8)

        ventas = (
            base_ventas
            + promocion * np.random.normal(3000, 800)
            + (inventario / 10000) * np.random.normal(200, 50)
            - abs(temperatura - 20) * np.random.normal(50, 10)
            + np.random.normal(0, 1000)
        )

        data.append({
             "tienda_id": tienda_id,
             "fecha": fecha,
             "ventas_semanales": max(0, round(ventas, 2)),
             "promocion_activa": promocion,
             "inventario_inicial": max(0, round(inventario, 0)),
             "temperatura_promedio": round(temperatura, 1)
             })

    #Crear DataFrame
    df= pd.DataFrame(data)

    # Ruta de salida
    ruta_salida = "content/tema1_ventas_retail.csv"

    # Guardar CSV
    df.to_csv(ruta_salida, index=False)

    df.head(), df.shape, f"Archivo generado en: {ruta_salida}"

"""### Paso 1: configuraci√≥n del entorno"""

# Instala las librer√≠as necesarias
# pip install plotly pandas scikit-learn

# Importa las librer√≠as
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import pickle

"""### üí° Nota:
siempre instala las librer√≠as al inicio del notebook para evitar errores de importaci√≥n

### Paso 2: configuraci√≥n centralizada de par√°metros
"""

# Configuraci√≥n centralizada - modifica aqu√≠ para cambiar todo el pipeline
CONFIG = {
    'data_path': 'content/tema1_ventas_retail.csv',
    'model_params': {
        'n_estimators': 100,
        'random_state': 42,
        'max_depth': 10
      },
    'test_size': 0.2,
    'target_column': 'ventas_semanales',
    'date_column': 'fecha',
    'store_column': 'tienda_id'
}
print(" ‚úÖConfiguraci√≥n cargada correctamente")
print(f"Modelo objetivo: {CONFIG['target_column']}")

"""### ¬øPor qu√© usar configuraci√≥n centralizada?
 Esto permite cambiar par√°metros en un solo lugar y hace el c√≥digo m√°s mantenible y profesional.

### Paso 3: Funci√≥n de carga y validaci√≥n de datos
"""

def cargar_y_validar_datos(ruta_archivo):
  """
  Carga y valida los datos de entrada
  """
  try:
    # Cargar datos
    df = pd.read_csv(ruta_archivo)
    print(f" ‚úÖDatos cargados: {df.shape[0]} filas, {df.shape[1]} columnas")
    # Validaciones b√°sicas
    columnas_requeridas = [CONFIG['target_column'], CONFIG['date_column'], CONFIG['store_column']]
    for col in columnas_requeridas:
      if col not in df.columns:
        raise ValueError(f" Columna requerida '{col}' no encontrada")

    # Convertir fecha
    df[CONFIG['date_column']] = pd.to_datetime(df[CONFIG['date_column']])

    # Verificar valores faltantes en target
    if df[CONFIG['target_column']].isnull().sum() > 0:
        print(f"‚ö†Ô∏è Advertencia: {df[CONFIG['target_column']].isnull().sum()} valores faltantes en target")
    print(" ‚úÖ Validaci√≥n de datos completada")
    return df
  except Exception as e:
      print(f"‚ùå Error al cargar los datos: {e}")
      return None

#Ejecutar funci√≥n
df= cargar_y_validar_datos(CONFIG['data_path'])

"""### üí° Nota:
las funciones de validaci√≥n previenen errores silenciosos que pueden arruinar tu modelo

### Paso 4: Funci√≥n de preprocesamiento
"""

def preprocesar_datos(df):
  """
  Preprocesa los datos para el modelo
  """
  print(" üîÑ Iniciando preprocesamiento...")
  # Crear features temporales
    #LINEA AGREGADA
  df[CONFIG['date_column']] = pd.to_datetime(df[CONFIG['date_column']], errors='coerce')
  df['a√±o'] = df[CONFIG['date_column']].dt.year
  df['mes'] = df[CONFIG['date_column']].dt.month
  df['semana'] = df[CONFIG['date_column']].dt.isocalendar().week
  df['dia_semana'] = df[CONFIG['date_column']].dt.dayofweek

  # Seleccionar features para el modelo
  feature_columns = ['tienda_id', 'a√±o', 'mes', 'semana', 'dia_semana', 'promocion_activa', 'inventario_inicial', 'temperatura_promedio']

  #verificar que todas las features existan
  features_disponibles = [col for col in feature_columns if col in df.columns]
  print(f"Features disponibles: {features_disponibles}")

  X = df[features_disponibles]
  y = df[CONFIG['target_column']]

  print(f"‚úÖ Preprocesamiento completado: {X.shape[1]} features")
  return X, y

# ejecutar preprocesamiento
X, y = preprocesar_datos(df)

"""### Paso 5: Funci√≥n de entrenamiento y evaluaci√≥n"""

def entrenar_y_evaluar_modelo(X, y):
  """
  Entrena el modelo y calcula m√©tricas
  """

  print("ü§ñ Iniciando entrenamiento del modelo...")

  # dividir datos
  X_train, X_test, y_train, y_test = train_test_split(
      X, y, test_size=CONFIG['test_size'], random_state=42
  )

  # Entrenar modelo
  modelo = RandomForestRegressor(**CONFIG['model_params'])
  modelo.fit(X_train, y_train)

  # Hacer predicciones
  y_pred = modelo.predict(X_test)

  # Calcular m√©tricas
  mae = mean_absolute_error(y_test, y_pred)
  r2 = r2_score(y_test, y_pred)

  metricas = {
      'mae': mae,
      'r2': r2,
      'fecha_entrenamiento': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
  }

  print(f"‚úÖ Modelo entrenado exitosamente")
  print(f"üìä MAE: {mae}")
  print(f"üìä R2: {r2}")

  return modelo, metricas, y_test, y_pred

# Ejecutar entrenamiento y evaluaci√≥n
modelo, metricas, y_test, y_pred = entrenar_y_evaluar_modelo(X, y)

"""### Paso 6: Funci√≥n de guardado del modelo

"""

def guardar_modelo_y_metricas(modelo, metricas):
  """
  Guarda el modelo y sus m√©tricas
  """
  timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

  # Guardar modelo
  nombre_modelo = f'modelo_ventas_{timestamp}.pkl'
  with open(nombre_modelo, 'wb') as f:
    pickle.dump(modelo, f)

  # guardar m√©tricas
  nombre_metricas = f'metricas_ventas_{timestamp}.txt'
  with open(nombre_metricas, 'w') as f:

    for key, value in metricas.items():
      f.write(f"{key}: {value}\n")

  print(f" ‚úÖModelo guardado como: {nombre_modelo}")
  print(f" ‚úÖM√©tricas guardadas como: {nombre_metricas}")
  return nombre_modelo, nombre_metricas

# Guardar modelo
archivo_modelo, archivo_metricas = guardar_modelo_y_metricas(modelo, metricas)

"""### **1.2.3 Reflexi√≥n final**

**¬øQu√© ventajas tiene este enfoque modular?** Cada funci√≥n tiene una responsabilidad espec√≠fica, lo que hace el c√≥digo m√°s f√°cil de mantener, debuggear y reutilizar.

üÜò!: Verifica que todas las columnas requeridas est√©n en tu dataset y que no haya errores de tipeo en los nombres de las columnas.

## 1.3 Sistema de reportes automaticos con visualizaciones
**Objetivo:** Crear reportes autom√°ticos con visualizaciones profesionales usando Plotty

### 1.3.1 Contexto
El equipo directivo de RetailMax necesita recibir reportes semanales autom√°ticos sobre el performance del modelo de predicci√≥n de ventas.

### 1.3.2 Instrucciones paso a paso

### Paso 1: Configuraci√≥n para reportes
"""

# Configuraci√≥n para reportes
REPORTE_CONFIG = {
    'titulo_empresa': 'RetailMax Analytics',
    'colores_corporativos': ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'],
    'template_plotly': 'plotly_white',
    'ruta_logo': None # Puedes agregar logo despu√©s
}
print("‚úÖ Configuraci√≥n de reporte cargada correctamente")

"""### Paso 2: Funci√≥n para m√©tricas de performance

"""

def generar_metricas_performance(y_real, y_pred):
  """
  Genera m√©tricas detalladas de performance del modelo
  """
  # Calcular m√©tricas b√°sicas
  mae = mean_absolute_error(y_real, y_pred)
  r2 = r2_score(y_real, y_pred)

  # Calcular m√©tricas adicionales
  mape = np.mean(np.abs((y_real - y_pred) / y_real)) * 100
  rmse = np.sqrt(np.mean((y_real - y_pred) ** 2))
  # Calcular accuracy personalizada (predicciones dentro del 10%)
  accuracy_10pct = np.mean(np.abs((y_real - y_pred) / y_real) <= 0.1) * 100
  metricas_detalladas = {
      'MAE (Error Absoluto Medio)': f"{mae:.2f}",
      'R¬≤ (Coeficiente Determinaci√≥n)': f"{r2:.3f}",
      'MAPE (Error Porcentual Medio)': f"{mape:.1f}%",
      'RMSE (Ra√≠z Error Cuadr√°tico)': f"{rmse:.2f}",
      'Accuracy ¬±10%': f"{accuracy_10pct:.1f}%"
  }
  return metricas_detalladas

# Generar m√©tricas
metricas_detalladas = generar_metricas_performance(y_test, y_pred)
print("üìä M√©tricas calculadas:")
# Convertir las m√©tricas en un DataFrame para una mejor visualizaci√≥n
metricas_df = pd.DataFrame(list(metricas_detalladas.items()), columns=['M√©trica', 'Valor'])
# con python en google colab funciona como display, en stream se cambia display por "st.dataframe"
st.dataframe(metricas_df)

"""### üí° Nota:
MAPE(Mean Absolute Percentage Error) es especialmente √∫til para comunicar error a audiencias de negocio porque est√° en porcentaje.

### Paso 3: Visualizaci√≥n de predicciones vs reales
"""

def crear_grafico_predicciones_vs_reales(y_real, y_pred):
  """
  Crea gr√°fico de dispersi√≥n predicciones vs valores reales
  """
  fig = go.Figure()
  # Scatter plot de predicciones vs reales
  fig.add_trace(go.Scatter(
      x=y_real, y=y_pred,
      mode='markers',
      name='Predicciones',
      marker=dict(
          color=REPORTE_CONFIG['colores_corporativos'][0],
          size=8,
          opacity=0.6
          ),
      hovertemplate='<b>Real:</b> %{x:.0f}<br><b>Predicci√≥n:</b> %{y:.0f}<extra></extra>' ))

  # L√≠nea de predicci√≥n perfecta
  min_val = min(min(y_real), min(y_pred))
  max_val = max(max(y_real), max(y_pred))
  fig.add_trace(go.Scatter(
      x=[min_val, max_val],
      y=[min_val, max_val],
      mode='lines',
      name='Predicci√≥n Perfecta',
      line=dict(color='red', dash='dash', width=2) ))
  # Configurar layout
  fig.update_layout(
      title={ 'text': 'Predicciones vs Valores Reales - Modelo de Ventas',
             'x': 0.5,
              'font': {'size': 16}
              },
      xaxis_title='Ventas Reales',
      yaxis_title='Ventas Predichas',
      template=REPORTE_CONFIG['template_plotly'],
      showlegend=True,
      width=700,
      height=500
      )
  return fig

# Crear y mostrar gr√°fico
fig_predicciones = crear_grafico_predicciones_vs_reales(y_test, y_pred)
fig_predicciones.show()

"""### **¬øPor qu√© este gr√°fico es importante?** Permite identificar visualmente si el modelo tiene sesgos sistem√°ticos o si hay rangos donde predice mejor.

### Paso 4: Gr√°fico de distribuci√≥n de errores
"""

def crear_grafico_distribucion_errores(y_real, y_pred):
   """
   Crea histograma de la distribuci√≥n de errores
   """
   errores = y_pred - y_real
   errores_porcentuales = ((y_pred - y_real) / y_real) * 100

   # Crear subplots
   from plotly.subplots import make_subplots

   fig = make_subplots(
       rows=1, cols=2,
       subplot_titles=('Distribuci√≥n de Errores Absolutos', 'Distribuci√≥n de Errores Porcentuales'),
       horizontal_spacing=0.1
       )

   # Histograma de errores absolutos
   fig.add_trace(
       go.Histogram(
           x=errores,
           nbinsx=30,
           name='Errores Absolutos',
           marker_color=REPORTE_CONFIG['colores_corporativos'][1],
           opacity=0.7
       ),
       row=1, col=1
   )
   # Histograma de errores porcentuales
   fig.add_trace(
       go.Histogram(
           x=errores_porcentuales,
           nbinsx=30,
           name='Errores Porcentuales',
           marker_color=REPORTE_CONFIG['colores_corporativos'][2],
           opacity=0.7
       ),
       row=1, col=2
   )
   # Configurar layout
   fig.update_layout(
       title={ 'text': 'An√°lisis de Errores del Modelo', 'x': 0.5, 'font': {'size': 16} },
       template=REPORTE_CONFIG['template_plotly'],
       showlegend=False,
       width=900,
       height=400
   )
   fig.update_xaxes(title_text="Error Absoluto", row=1, col=1)
   fig.update_xaxes(title_text="Error Porcentual (%)", row=1, col=2)
   fig.update_yaxes(title_text="Frecuencia", row=1, col=1)
   fig.update_yaxes(title_text="Frecuencia", row=1, col=2)
   return fig

# Crear y mostrar gr√°fico
fig_errores = crear_grafico_distribucion_errores(y_test, y_pred)
fig_errores.show()

"""### Paso 5: Feature importance interactivo"""

def crear_grafico_feature_importance(modelo, feature_names):
   """
   Crea gr√°fico interactivo de importancia de features
   """

   # Obtener importancias
   importancias = modelo.feature_importances_

   # Crear DataFrame para ordenar
   df_importance = pd.DataFrame({ 'feature': feature_names, 'importancia': importancias }).sort_values('importancia', ascending=True)

   # Crear gr√°fico de barras horizontal
   fig = go.Figure(go.Bar(
       x=df_importance['importancia'],
       y=df_importance['feature'],
       orientation='h',
       marker=dict(
           color=df_importance['importancia'],
           colorscale='Viridis',
           showscale=True,
           colorbar=dict(title="Importancia")
       ),
       hovertemplate='<b>%{y}</b><br>Importancia: %{x:.3f}<extra></extra>'
   ))

   fig.update_layout(
       title={ 'text': 'Importancia de Variables en el Modelo', 'x': 0.5, 'font': {'size': 16} },
       xaxis_title='Importancia',
       yaxis_title='Variables',
       template=REPORTE_CONFIG['template_plotly'],
       width=700,
       height=500
   )
   return fig

# Crear y mostrar gr√°fico
fig_importance = crear_grafico_feature_importance(modelo, X.columns)
fig_importance.show()

"""### Paso 6: Funci√≥n de reporte completo"""

def generar_reporte_completo(modelo, metricas, y_real, y_pred, feature_names):
  """
  Genera reporte HTML completo con todas las visualizaciones
  """
  from datetime import datetime

  # Crear HTML del reporte
  html_content = f"""
  <!DOCTYPE html>
  <html>
  <head>
  <title>Reporte de Performance - Modelo de Ventas RetailMax</title>
  <style>
  body {{ font-family: Arial, sans-serif; margin: 40px; }}
  .header {{ text-align: center; color: #1f77b4; }}
  .metrics {{ background-color: #f8f9fa; padding: 20px; border-radius: 5px; margin: 20px 0; }}
  .metric {{ display: inline-block; margin: 10px 20px; }}
  .timestamp {{ color: #666; font-size: 12px; }}
  </style>
  </head>
  <body>
  <div class="header">
  <h1> üè™RetailMax Analytics</h1>
  <h2>Reporte de Performance - Modelo de Predicci√≥n de Ventas</h2>
  <p class="timestamp">Generado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
  </div>

  <div class="metrics">
  <h3> üìäM√©tricas de Performance</h3>
  """

  # Agregar m√©tricas
  for metrica, valor in metricas.items():
    html_content += f'<div class="metric"><strong>{metrica}:</strong> {valor}</div>'

  html_content += f"""
  </div>
  <h3> üìàVisualizaciones</h3>
  <p>Las visualizaciones interactivas se han generado por separado. Incluye:</p>
  <ul>
  <li>Gr√°fico de Predicciones vs Valores Reales</li>
  <li>Distribuci√≥n de Errores</li>
  <li>Importancia de Variables</li>
  </ul>
  <h3> üí°Insights Clave</h3>
  <ul>
  <li>El modelo muestra un R¬≤ de {metricas['R¬≤ (Coeficiente Determinaci√≥n)']}, indicando un buen ajuste</li>
  <li>El error porcentual promedio es de {metricas['MAPE (Error Porcentual Medio)']}</li>
  <li>El {metricas['Accuracy ¬±10%']} de las predicciones est√°n dentro del ¬±10% del valor real</li>
  </ul>
  <h3> üéØRecomendaciones</h3>
  <ul>
  <li>Continuar monitoreando el performance del modelo semanalmente</li>
  <li>Considerar reentrenamiento si el error aumenta significativamente</li>
  <li>Evaluar la incorporaci√≥n de nuevas variables externas</li>
  </ul>
  </body>
  </html>
  """
  # Guardar reporte
  timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
  nombre_reporte = f'reporte_ventas_{timestamp}.html'
  with open(nombre_reporte, 'w', encoding='utf-8') as f:
    f.write(html_content)

  print(f" ‚úÖReporte HTML generado: {nombre_reporte}")
  return nombre_reporte

# Generar reporte completo
archivo_reporte = generar_reporte_completo(modelo, metricas_detalladas, y_test, y_pred, X.columns)

"""### 1.3.3 Reflexi√≥n final
**¬øC√≥mo beneficia esto al negocio?** Los reportes autom√°ticos aseguran que los stakeholders reciban informaci√≥n consistente y actualizada sin intervenci√≥n manual, mejorando la toma de decisiones.

üÜò!: Aseg√∫rate de que Plotly est√© instalado correctamente y que las variables y_test e y_pred contengan datos v√°lidos.

## 1.4 Configuraci√≥n de ejecuci√≥n programada con Google Apps Script

**Objetivo:** Implementar un sistema b√°sico de ejecuci√≥n programada para el pipeline ML

### 1.4.1 Contexto

RetailMax necesita que el modelo se actualice autom√°ticamente cada lunes con los datos de la semana anterior, sin intervenci√≥n manual.

### 1.4.2 Instrucciones paso a paso

### Paso 1: Preparaci√≥n del notebook para ejecuci√≥n autom√°tica
Primero, necesitas modificar tu notebook para que sea completamente aut√≥nomo:
"""

# Configuraci√≥n para ejecuci√≥n autom√°tica
import os
from datetime import datetime, timedelta
import logging

# Configurar logging para ejecuci√≥n autom√°tica
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ejecucion_automatica.log'),
        logging.StreamHandler()
    ]
)

def log_inicio_ejecucion():
    """Registra el inicio de la ejecuci√≥n autom√°tica"""
    logging.info("="*50)
    logging.info("INICIO DE EJECUCI√ìN AUTOM√ÅTICA")
    logging.info(f"Timestamp: {datetime.now()}")
    logging.info("="*50)

def log_fin_ejecucion(exitoso=True):
    """Registra el fin de la ejecuci√≥n"""
    status = "EXITOSA" if exitoso else "FALLIDA"
    logging.info("="*50)
    logging.info(f"FIN DE EJECUCI√ìN - {status}")
    logging.info(f"Timestamp: {datetime.now()}")
    logging.info("="*50)

# Iniciar logging
log_inicio_ejecucion()

"""### üí°Nota:
 El logging es crucial para ejecuciones autom√°ticas porque no estar√°s presente para ver errores en tiempo real.

### Paso 2: Funci√≥n de verificaci√≥n de datos nuevos
"""

def verificar_datos_nuevos(ruta_archivo, dias_atras=7):
  """
  Verifica si hay datos nuevos en el archivo
  """
  try:
    df = pd.read_csv(ruta_archivo)
    df['fecha'] = pd.to_datetime(df['fecha'])

    # Verificar fecha m√°s reciente
    fecha_mas_reciente = df['fecha'].max()
    fecha_limite = datetime.now() - timedelta(days=dias_atras)
    hay_datos_nuevos = fecha_mas_reciente >= fecha_limite

    logging.info(f"Fecha m√°s reciente en datos: {fecha_mas_reciente}")
    logging.info(f"Fecha l√≠mite para considerar 'nuevos': {fecha_limite}")
    logging.info(f"¬øHay datos nuevos?: {hay_datos_nuevos}")

    return hay_datos_nuevos, fecha_mas_reciente
  except Exception as e:
    logging.error(f"Error verificando datos nuevos: {e}")
    return False, None

# Verificar datos
hay_nuevos, fecha_reciente = verificar_datos_nuevos(CONFIG['data_path'])

"""**¬øPor qu√© verificar datos nuevos?** Evita reentrenar el modelo innecesariamente si no hay datos frescos, ahorrando recursos computacionales.

### Paso 3: Pipeline completo con manejo de errores
"""

def ejecutar_pipeline_completo():
  """ Ejecuta el pipeline completo con manejo de errores """
  try:
    logging.info("Iniciando pipeline completo...")
    # Paso 1: Cargar datos
    logging.info("Paso 1: Cargando datos...")
    df = cargar_y_validar_datos(CONFIG['data_path'])
    if df is None:
      raise Exception("Error al cargar datos")

    # Paso 2: Preprocesar
    logging.info("Paso 2: Preprocesando datos...")
    X, y = preprocesar_datos(df)

    # Paso 3: Entrenar modelo
    logging.info("Paso 3: Entrenando modelo...")
    modelo, metricas, y_test, y_pred = entrenar_y_evaluar_modelo(X, y)

    # Paso 4: Guardar modelo
    logging.info("Paso 4: Guardando modelo...")
    archivo_modelo, archivo_metricas = guardar_modelo_y_metricas(modelo, metricas)

    # Paso 5: Generar reporte
    logging.info("Paso 5: Generando reporte...")
    metricas_detalladas = generar_metricas_performance(y_test, y_pred)
    archivo_reporte = generar_reporte_completo(modelo, metricas_detalladas, y_test, y_pred, X.columns)

    # Paso 6: Notificar √©xito
    logging.info(" ‚úÖPipeline ejecutado exitosamente")
    logging.info(f"Archivos generados:")
    logging.info(f" - Modelo: {archivo_modelo}")
    logging.info(f" - M√©tricas: {archivo_metricas}")
    logging.info(f" - Reporte: {archivo_reporte}")
    return True, { 'modelo': archivo_modelo, 'metricas': archivo_metricas, 'reporte': archivo_reporte }
  except Exception as e:
    logging.error(f" ‚ùåError en pipeline: {e}")
    return False, None

# Ejecutar pipeline si hay datos nuevos
if hay_nuevos:
  exito, archivos = ejecutar_pipeline_completo()
  log_fin_ejecucion(exito)
else:
  logging.info("No hay datos nuevos. Saltando ejecuci√≥n.")
  log_fin_ejecucion(True)

"""### Paso 4: configuraci√≥n de Google apps script
Ahora crear√°s un script en Google Apps Script para ejecutar tu notebook:


1.   Ve a script.google.com
2.   Crea un nuevo proyecto
3.   Reemplaza el c√≥digo por defecto con: **Texto comentado en bloque siguiente**
4.  Asegurate de guardar!

/** * Script para ejecutar notebook de ML autom√°ticamente
 * RetailMax - Sistema de Predicci√≥n de Ventas
 */
function ejecutarNotebookML() {
  console.log('Iniciando ejecuci√≥n programada del notebook ML');

  try {
    // Configuraci√≥n
    const NOTEBOOK_URL = 'TU_URL_DE_COLAB_AQUI'; // Reemplaza con tu URL
    const EMAIL_NOTIFICACION = 'tu-email@empresa.com'; // Tu email

    // Registrar inicio
    console.log(`Timestamp: ${new Date()}`);

    // Simular ejecuci√≥n del notebook
    const resultado = simularEjecucionNotebook();

    if (resultado.exito) {
      enviarNotificacionExito(EMAIL_NOTIFICACION, resultado);
      console.log('‚úÖ Ejecuci√≥n completada exitosamente');
    } else {
      enviarNotificacionError(EMAIL_NOTIFICACION, resultado.error);
      console.log('‚ùå Ejecuci√≥n fall√≥');
    }
  } catch (error) {
    console.error('Error en ejecuci√≥n programada:', error);
    // Nota: EMAIL_NOTIFICACION debe estar definido fuera del try si se usa aqu√≠,
    // o repetirse dentro del catch para evitar errores de referencia.
    const emailFallback = 'tu-email@empresa.com';
    enviarNotificacionError(emailFallback, error.toString());
  }
}

function simularEjecucionNotebook() {
  // Simula la ejecuci√≥n del notebook
  const exito = Math.random() > 0.1; // 90% de probabilidad de √©xito

  if (exito) {
    return {
      exito: true,
      timestamp: new Date(),
      archivos_generados: [
        'modelo_ventas_20240315_143022.pkl',
        'reporte_ventas_20240315_143022.html'
      ]
    };
  } else {
    return {
      exito: false,
      error: 'Error simulado en la ejecuci√≥n del modelo'
    };
  }
}

function enviarNotificacionExito(email, resultado) {
  const asunto = '‚úÖ RetailMax ML - Ejecuci√≥n Exitosa';
  const cuerpo = `
    Hola,
    El modelo de predicci√≥n de ventas se ha ejecutado exitosamente.

    üìä Detalles de la ejecuci√≥n:
    - Timestamp: ${resultado.timestamp}
    - Archivos generados: ${resultado.archivos_generados.join(', ')}

    El nuevo modelo est√° listo para usar en producci√≥n.

    Saludos,
    Sistema Automatizado RetailMax
  `;

  GmailApp.sendEmail(email, asunto, cuerpo);
  console.log(`Notificaci√≥n de √©xito enviada a ${email}`);
}

function enviarNotificacionError(email, error) {
  const asunto = '‚ùå RetailMax ML - Error en Ejecuci√≥n';
  const cuerpo = `
    Hola,
    Ha ocurrido un error en la ejecuci√≥n autom√°tica del modelo de predicci√≥n de ventas.

    üö® Error reportado:
    ${error}

    Por favor, revisa el notebook y los logs para m√°s detalles.

    Saludos,
    Sistema Automatizado RetailMax
  `;

  GmailApp.sendEmail(email, asunto, cuerpo);
  console.log(`Notificaci√≥n de error enviada a ${email}`);
}

function configurarTriggerSemanal() {
  // Eliminar triggers existentes para evitar duplicados
  const triggers = ScriptApp.getProjectTriggers();
  triggers.forEach(trigger => {
    if (trigger.getHandlerFunction() === 'ejecutarNotebookML') {
      ScriptApp.deleteTrigger(trigger);
    }
  });

  // Crear nuevo trigger para ejecutar cada lunes a las 8:00 AM
  ScriptApp.newTrigger('ejecutarNotebookML')
    .timeBased()
    .everyWeeks(1)
    .onWeekDay(ScriptApp.WeekDay.MONDAY)
    .atHour(8)
    .create();

  console.log('‚úÖ Trigger semanal configurado para los lunes a las 8:00 AM');
}

### üí°Nota:
Google Apps Script tiene l√≠mites de tiempo de ejecuci√≥n. Para notebooks complejos, considera usar Google Cloud Functions.

### Paso 5: configurar el trigger autom√°tico
En google apps script:
1. Haz clic en el √≠cono del reloj (‚è∞) en la barra lateral izquierda
2. Haz clic en "+ agregar activador" (triggers)
3. Configura:

    * Funci√≥n a ejecutar: ejecutarNotebookML
    * Origen del evento: Basado en tiempo
    * Tipo de activador basado en tiempo: Activador semanal
    * D√≠a de la semana: Lunes
    * Hora del d√≠a: 8 a 9

4. Dale permiso a google de que este script Acceda a tu cuenta

### Paso 6: Funci√≥n de monitoreo de ejecuciones
"""

def crear_log_ejecuciones():
  """
  Crea un sistema de logging para monitorear ejecuciones
  """
  log_data = {
      'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
      'exito': True, # Se actualizar√° seg√∫n el resultado
      'duracion_minutos': 0, # Se calcular√°
      'archivos_generados': [],
      'metricas_modelo': {},
      'errores': []
  }
  return log_data
def guardar_log_ejecucion(log_data):

  """
  Guarda el log de ejecuci√≥n en un archivo CSV
  """
  import csv
  import os

  archivo_log = 'historial_ejecuciones.csv'
  # Verificar si el archivo existe
  archivo_existe = os.path.exists(archivo_log)
  with open(archivo_log, 'a', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)

    # Escribir header si es archivo nuevo
    if not archivo_existe:
      writer.writerow(['timestamp', 'exito', 'duracion_minutos', 'archivos_generados', 'errores'])
    # Escribir datos
    writer.writerow([
        log_data['timestamp'],
        log_data['exito'],
        log_data['duracion_minutos'],
        ';'.join(log_data['archivos_generados']),
        ';'.join(log_data['errores'])
    ])
    print(f" ‚úÖLog guardado en {archivo_log}")

# Ejemplo de uso del sistema de logging
log_ejecucion = crear_log_ejecuciones()
# ... ejecutar pipeline ...
log_ejecucion['exito'] = True
log_ejecucion['archivos_generados'] = ['modelo.pkl', 'reporte.html']
guardar_log_ejecucion(log_ejecucion)

"""### 1.4.3 Reflexi√≥n final
**¬øQu√© valor aporta la automatizaci√≥n?** Reduce errores humanos, asegura consistencia en las ejecuciones, y libera tiempo del equipo para tareas de mayor valor agregado.

üÜò!: Verifica que tengas permisos para crear triggers en Google Apps Script y que tu email est√© correctamente configurado para recibir notificaciones.

## 1.5 Dashboard Interactivo con Streamlit Cloud

**Objetivo:** Crear una aplicaci√≥n web interactiva para que usuarios finales interact√∫en con el modelo

### 1.5.1 Contexto
Los gerentes de tienda de RetailMax necesitan una herramienta f√°cil de usar para predecir ventas semanales bas√°ndose en diferentes escenarios (promociones, inventario, clima).

### 1.5.2 Instrucciones paso a paso

### Paso 1: Configuraci√≥n del entorno streamlit

Crea un archivo Python llamado app_ventas_retail.py o un nuevo notebook y descargalo como app_ventas_retail.py:
"""

# Importaciones necesarias
# !pip install streamlit
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pickle
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de la p√°gina
st.set_page_config( page_title="RetailMax - Predictor de Ventas",
                   page_icon="üè™ ",
                    layout="wide",
                    initial_sidebar_state="expanded"
)
# CSS personalizado para mejorar la apariencia
st.markdown("""
<style>
    .main-header {
      font-size: 2.5rem;
      color: #1f77b4;
      text-align: center;
      margin-bottom: 2rem;
    }
      .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
     }
     .sidebar .sidebar-content {
        background-color: #f0f2f6; }
</style>
""", unsafe_allow_html=True)
print(" ‚úÖConfiguraci√≥n inicial de Streamlit completada")

"""### üí° Nota:
La configuraci√≥n de p√°gina debe ser lo primero que ejecutes en Streamlit, antes de cualquier otro comando st.

### Paso 2: Funci√≥n de carga del modelo
"""

@st.cache_data
def cargar_datos_demo():
   """
   Carga datos de demostraci√≥n para la app
   """
   # Crear datos sint√©ticos para demostraci√≥n
   np.random.seed(42)

   tiendas = [f"Tienda_{i:02d}" for i in range(1, 21)]
   fechas = pd.date_range(start='2024-01-01', end='2024-03-15', freq='W')
   data = []
   for tienda in tiendas:
    for fecha in fechas:
      data.append({
          'tienda_id': tienda,
          'fecha': fecha,
          'ventas_semanales': np.random.normal(15000, 3000),
          'promocion_activa': np.random.choice([0, 1], p=[0.7, 0.3]),
          'inventario_inicial': np.random.normal(50000, 10000),
          'temperatura_promedio': np.random.normal(20, 8),
          'a√±o': fecha.year, 'mes': fecha.month,
          'semana': fecha.isocalendar().week,
          'dia_semana': fecha.dayofweek
      })
   return pd.DataFrame(data)

@st.cache_resource
def cargar_modelo_demo():
  """
  Carga o crea un modelo de demostraci√≥n
  """
  # Para demostraci√≥n, creamos un modelo simple
  from sklearn.ensemble import RandomForestRegressor
  from sklearn.model_selection import train_test_split

  # Cargar datos
  df = cargar_datos_demo()

  # Preparar features
  feature_columns = ['promocion_activa', 'inventario_inicial', 'temperatura_promedio', 'a√±o', 'mes', 'semana', 'dia_semana']
  X = df[feature_columns]
  y = df['ventas_semanales']

  # Entrenar modelo
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
  modelo = RandomForestRegressor(n_estimators=100, random_state=42)
  modelo.fit(X_train, y_train)
  return modelo, feature_columns

# Cargar modelo y datos globalmente
modelo, feature_columns = cargar_modelo_demo()
df_historico = cargar_datos_demo()
st.success(" ‚úÖModelo y datos cargados exitosamente")

"""###
**¬øPor qu√© usar @st.cache?** Evita recargar datos y modelos en cada interacci√≥n del usuario, mejorando significativamente la velocidad de la app.

### Paso 3: Sidebar con Controles de Entrada
"""

def crear_sidebar():
  """
  Crea la barra lateral con controles de entrada
  """
  st.sidebar.markdown("## üé≤Configuraci√≥n de Predicci√≥n")
  # Selecci√≥n de tienda
  tiendas_disponibles = df_historico['tienda_id'].unique()
  tienda_seleccionada = st.sidebar.selectbox(
      " üè™Selecciona la tienda:",
      options=tiendas_disponibles,
      help="Elige la tienda para la cual quieres hacer la predicci√≥n" )

  # Fecha de predicci√≥n
  fecha_prediccion = st.sidebar.date_input(
      "üìÖ Fecha de la semana a predecir:",
      value=datetime.now() + timedelta(days=7),
      help="Selecciona la fecha de inicio de la semana" )
  # Promoci√≥n activa
  promocion_activa = st.sidebar.radio(
      "üéØ ¬øHabr√° promoci√≥n activa?",
      options=[0, 1],
      format_func=lambda x: "No" if x == 0 else "S√≠",
      help="Indica si habr√° una promoci√≥n especial durante la semana" )
  # Inventario inicial
  inventario_inicial = st.sidebar.slider(
      "üì¶ Inventario inicial (unidades):",
      min_value=20000,
      max_value=80000,
      value=50000,
      step=1000,
      help="Cantidad de productos disponibles al inicio de la semana"
  )
  # Temperatura promedio
  temperatura_promedio = st.sidebar.slider(
      "üå°Ô∏è Temperatura promedio esperada (¬∞C):",
      min_value=-10,
      max_value=40,
      value=20,
      step=1,
      help="Temperatura promedio esperada durante la semana"
  )
  # Bot√≥n de predicci√≥n
  predecir = st.sidebar.button(
      "üîÆ Hacer Predicci√≥n",
      type="primary",
      help="Haz clic para generar la predicci√≥n con los par√°metros seleccionados"
  )

  return {
      'tienda': tienda_seleccionada,
      'fecha': fecha_prediccion,
      'promocion': promocion_activa,
      'inventario': inventario_inicial,
      'temperatura': temperatura_promedio,
      'predecir': predecir
  }
  # Crear sidebar
  parametros = crear_sidebar()

"""### Paso 4: Funci√≥n de predicci√≥n"""

def hacer_prediccion(parametros):
  """
  Realiza la predicci√≥n basada en los par√°metros de entrada
  """
  # Preparar datos para predicci√≥n
  fecha = pd.to_datetime(parametros['fecha'])

  datos_prediccion = pd.DataFrame({
      'promocion_activa': [parametros['promocion']],
      'inventario_inicial': [parametros['inventario']],
      'temperatura_promedio': [parametros['temperatura']],
      'a√±o': [fecha.year], 'mes': [fecha.month],
      'semana': [fecha.isocalendar().week],
      'dia_semana': [fecha.dayofweek]
  })
  # Hacer predicci√≥n
  prediccion = modelo.predict(datos_prediccion)[0]

  # Calcular intervalo de confianza (simulado)
  std_error = prediccion * 0.15 # 15% de error est√°ndar estimado
  intervalo_inferior = prediccion - 1.96 * std_error
  intervalo_superior = prediccion + 1.96 * std_error
  return {
      'prediccion': prediccion,
      'intervalo_inferior': max(0, intervalo_inferior),
      'intervalo_superior': intervalo_superior,
      'confianza': 95
  }
def mostrar_resultados_prediccion(resultado, parametros):
  """
  Muestra los resultados de la predicci√≥n de manera atractiva
  """
  st.markdown("##üìä Resultados de la Predicci√≥n")
  # M√©tricas principales
  col1, col2, col3 = st.columns(3)

  with col1:
    st.metric(
        label="üí∞Ventas Predichas",
        value=f"${resultado['prediccion']:,.0f}",
        help="Predicci√≥n puntual de ventas para la semana"
    )
  with col2:
    st.metric(
        label=" üìâRango M√≠nimo",
        value=f"${resultado['intervalo_inferior']:,.0f}",
        help=f"L√≠mite inferior del intervalo de confianza al {resultado['confianza']}%"
    )
  with col3:
    st.metric(
        label="üìà Rango M√°ximo",
        value=f"${resultado['intervalo_superior']:,.0f}",
        help=f"L√≠mite superior del intervalo de confianza al {resultado['confianza']}%"
    )
    # Gr√°fico de gauge
    fig_gauge = go.Figure(go.Indicator(
        mode = "gauge+number+delta",
        value = resultado['prediccion'],
        domain = {'x': [0, 1], 'y': [0, 1]},
        title = {'text': "Ventas Predichas ($)"},
        delta = {'reference': df_historico[df_historico['tienda_id'] == parametros['tienda']]['ventas_semanales'].mean()},
        gauge = {
            'axis': {'range': [None, 30000]},
            'bar': {'color': "darkblue"},
            'steps': [ {'range': [0, 10000], 'color': "lightgray"},
                       {'range': [10000, 20000], 'color': "gray"},
                       {'range': [20000, 30000], 'color': "lightgreen"}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': resultado['prediccion']
                }
            }
        ))
    fig_gauge.update_layout(height=400)
    st.plotly_chart(fig_gauge, use_container_width=True)

"""### Paso 5: An√°lisis comparativo"""

def crear_analisis_comparativo(parametros, resultado):
  """
  Crea an√°lisis comparativo con datos hist√≥ricos
  """
  st.markdown("## üìàAn√°lisis Comparativo")
  # Filtrar datos hist√≥ricos de la tienda
  datos_tienda = df_historico[df_historico['tienda_id'] == parametros['tienda']].copy()
  datos_tienda = datos_tienda.sort_values('fecha')

  # Crear gr√°fico de serie temporal
  fig_temporal = go.Figure()
  # Ventas hist√≥ricas
  fig_temporal.add_trace(go.Scatter(
      x=datos_tienda['fecha'],
      y=datos_tienda['ventas_semanales'],
      mode='lines+markers',
      name='Ventas Hist√≥ricas',
      line=dict(color='blue', width=2),
      marker=dict(size=6)
  ))

  # Predicci√≥n
  fig_temporal.add_trace(go.Scatter(
      x=[parametros['fecha']],
      y=[resultado['prediccion']],
      mode='markers',
      name='Predicci√≥n',
      marker=dict(color='red', size=12, symbol='star')
  ))

  # Intervalo de confianza
  fig_temporal.add_trace(go.Scatter(
       x=[parametros['fecha'], parametros['fecha']],
       y=[resultado['intervalo_inferior'], resultado['intervalo_superior']],
       mode='lines', name=f'Intervalo {resultado["confianza"]}%',
       line=dict(color='red', dash='dash'),
       showlegend=False
  ))
  fig_temporal.update_layout(
      title=f'Evoluci√≥n de Ventas - {parametros["tienda"]}',
      xaxis_title='Fecha',
      yaxis_title='Ventas Semanales ($)',
      hovermode ='x unified',
      height=500
  )
  st.plotly_chart(fig_temporal, use_container_width=True)
  # Estad√≠sticas comparativas
  col1, col2 = st.columns(2)

  with col1:
    st.markdown("###üìä Estad√≠sticas Hist√≥ricas")
    promedio_historico = datos_tienda['ventas_semanales'].mean()
    std_historico = datos_tienda['ventas_semanales'].std()
    st.write(f"**Promedio hist√≥rico:** ${promedio_historico:,.0f}")
    st.write(f"**Desviaci√≥n est√°ndar:** ${std_historico:,.0f}")
    st.write(f"**Ventas m√°ximas:** ${datos_tienda['ventas_semanales'].max():,.0f}")
    st.write(f"**Ventas m√≠nimas:** ${datos_tienda['ventas_semanales'].min():,.0f}")

  with col2:
    st.markdown("### Comparaci√≥n con Predicci√≥n")
    diferencia = resultado['prediccion'] - promedio_historico
    porcentaje_diferencia = (diferencia / promedio_historico) * 100
    if diferencia > 0:
      st.success(f"**${diferencia:,.0f}** por encima del promedio ({porcentaje_diferencia:+.1f}%) ")
    else:
        st.warning(f"**${abs(diferencia):,.0f}** por debajo del promedio ({porcentaje_diferencia:+.1f}%) ")
    # Percentil de la predicci√≥n
    percentil = (datos_tienda['ventas_semanales'] < resultado['prediccion']).mean() * 100
    st.info(f"La predicci√≥n est√° en el **percentil {percentil:.0f}** de ventas hist√≥ricas")

def crear_analisis_sensibilidad():
  """
  Crea an√°lisis de sensibilidad para diferentes escenarios
  """
  st.markdown("## üîçAn√°lisis de Sensibilidad")
  st.markdown("Explora c√≥mo diferentes factores afectan las predicciones:")
  # An√°lisis de promociones
  escenarios_promocion = []
  for promo in [0, 1]:
    datos_escenario = pd.DataFrame({
        'promocion_activa': [promo],
        'inventario_inicial': [50000],
        'temperatura_promedio': [20],
        'a√±o': [2024], 'mes': [3],
        'semana': [12],
        'dia_semana': [0]
    })
    pred = modelo.predict(datos_escenario)[0]
    escenarios_promocion.append({
        'Escenario': 'Con Promoci√≥n' if promo else 'Sin Promoci√≥n',
        'Ventas_Predichas': pred
    })
  df_promocion = pd.DataFrame(escenarios_promocion)
  fig_promocion = px.bar(
      df_promocion,
      x='Escenario',
      y='Ventas_Predichas',
      title='Impacto de las Promociones en las Ventas',
      color='Ventas_Predichas',
      color_continuous_scale='Blues'
    )
  fig_promocion.update_layout(height=400)
  st.plotly_chart(fig_promocion, use_container_width=True)
  # Mostrar diferencia
  diferencia_promocion = df_promocion.iloc[1]['Ventas_Predichas'] - df_promocion.iloc[0]['Ventas_Predichas']
  st.info(f"üí° **Insight:** Las promociones aumentan las ventas en aproximadamente **${diferencia_promocion:,.0f}** ({(diferencia_promocion/df_promocion.iloc[0]['Ventas_Predichas']*100):+.1f}%) ")

"""### Paso 6: P√°gina principal de la app"""

def main():
  """
  Funci√≥n principal de la aplicaci√≥n
  """
  # Header principal
  st.markdown('<h1 class="main-header"> üè™RetailMax - Predictor de Ventas</h1>', unsafe_allow_html=True)

  st.markdown("""
  ### Bienvenido al Sistema de Predicci√≥n de Ventas
  Esta herramienta te permite predecir las ventas semanales de cualquier tienda RetailMax bas√°ndose en factores como promociones, inventario y condiciones clim√°ticas.
  **Intrucciones:**
  1. üìùConfigura los par√°metros en la barra lateral
  2. üîÆHaz clic en "Hacer Predicci√≥n"
  3. üìäAnaliza los resultados y comparaciones
  """)

  # Obtener los par√°metros de la barra lateral
  parametros = crear_sidebar()

  # Verificar si se debe hacer predicci√≥n
  if parametros['predecir']:
    with st.spinner('üîÑ Generando predicci√≥n...'):
      resultado = hacer_prediccion(parametros)
      # Mostrar resultados
      mostrar_resultados_prediccion(resultado, parametros)
      # An√°lisis comparativo
      crear_analisis_comparativo(parametros, resultado)
      # An√°lisis de sensibilidad
      crear_analisis_sensibilidad()
      # Bot√≥n de descarga de resultados
      st.markdown("## üíæ Descargar Resultados")
      resultados_descarga = {
          'Tienda': parametros['tienda'],
          'Fecha_Prediccion': str(parametros['fecha']),
          'Promocion_Activa': 'S√≠' if parametros['promocion'] else 'No',
          'Inventario_Inicial': parametros['inventario'],
          'Temperatura_Promedio': parametros['temperatura'],
          'Ventas_Predichas': f"${resultado['prediccion']:,.0f}",
          'Rango_Minimo': f"${resultado['intervalo_inferior']:,.0f}",
          'Rango_Maximo': f"${resultado['intervalo_superior']:,.0f}",
          'Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
      }
    df_descarga = pd.DataFrame([resultados_descarga])
    csv_descarga = df_descarga.to_csv(index=False)
    st.download_button(
        label=" ‚¨áÔ∏èDescargar Predicci√≥n (CSV)",
        data=csv_descarga, file_name=f"prediccion_ventas_{parametros['tienda']}_{parametros['fecha']}.csv",
        mime="text/csv"
    )
  else:
    # Mostrar informaci√≥n general cuando no hay predicci√≥n
    st.markdown("## üìàDashboard General")
    # M√©tricas generales
    col1, col2, col3, col4 = st.columns(4)

    with col1:
      st.metric(" üè™Total Tiendas", len(df_historico['tienda_id'].unique()))

    with col2:
      st.metric(" üìÖSemanas de Datos", len(df_historico['fecha'].unique()))

    with col3:
      promedio_general = df_historico['ventas_semanales'].mean()
      st.metric("üí∞ Promedio Ventas", f"${promedio_general:,.0f}")

    with col4:
      total_ventas = df_historico['ventas_semanales'].sum()
      st.metric("üíé Ventas Totales", f"${total_ventas:,.0f}")
    # Gr√°fico de ventas por tienda
    ventas_por_tienda = df_historico.groupby('tienda_id')['ventas_semanales'].mean().sort_values(ascending=False)
    fig_tiendas = px.bar(
        x=ventas_por_tienda.index,
        y=ventas_por_tienda.values,
        title='Promedio de Ventas por Tienda',
        labels={'x': 'Tienda', 'y': 'Ventas Promedio ($)'}
    )
    fig_tiendas.update_layout(height=500)
    st.plotly_chart(fig_tiendas, use_container_width=True)

# Ejecutar aplicaci√≥n principal
if __name__ == "__main__":
  main()

"""![image.png](data:image/png;base64,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)

 ### Crear repositorio en GitHub

#### Paso 1:

* Crear un repositorio p√∫blico
* sube tu archivo *app_ventas_retail.py*
* crear un archivo *requirements.txt* con:
  * streamlit
  * pandas
  * numpy
  * plotly
  * scikit-learn

#### Paso 2:

* Ve a
[share.streamlit.io](https://share.streamlit.io/)

* Conecta tu cuenta de GitHub,
si no tienes, la puedes crear

* Selecciona tu repositorio

* Especifica
app_ventas_retail.py
como archivo principal
* Haz clic en ‚ÄúDeploy‚Äù
"""
### 1.5.4 Entregables
* aplicaci√≥n streamlit completamente funcional
* App desplegada en Streamlit Cloud (URL p√∫blica)

### 1.5.5 Reflexi√≥n final
**C√≥mo mejora esto la toma de decisiones?**
La aplicaci√≥n democratiza el acceso al modelo ML,
permitiendo que usuarios no t√©cnicos exploren escenarios y tomen decisiones informadas
basadas en predicciones.

#üÜò!:
Verifica que todas las librer√≠as est√©n instaladas correctamente y que el modelo se cargue
sin errores.
Streamlit mostrar√° errores detallados en la interfaz.

## 1.6 Dashboard ejecutivo en Google Data Studio

**Objetivo:** Crear un dashboard profesional para ejecutivos con m√©tricas del modelo ML

### 1.6.1 Contexto
La direcci√≥n de RetailMax necesita un dashboard ejecutivo que se actualice autom√°ticamente
con las m√©tricas del modelo de predicci√≥n de ventas y muestre KPIs cr√≠ticos para la toma de
decisiones estrat√©gicas.

### 1.6.2 instrucciones paso a paso

#### Paso 1: preparaci√≥n de datos para google sheets
"""

# Configuraci√≥n para integraci√≥n con Google Sheets
import gspread
from google.oauth2.service_account import Credentials
import json
from datetime import datetime, timedelta
# Configuraci√≥n de Google Sheets
SHEETS_CONFIG = {
'spreadsheet_name': 'RetailMax_ML_Dashboard_Data',
'worksheets': {
'metricas_modelo': 'Metricas_Modelo',
'predicciones_semanales': 'Predicciones_Semanales',
'performance_tiendas': 'Performance_Tiendas',
'alertas': 'Alertas'
}
}
def configurar_google_sheets():
  """
  Configura la conexi√≥n con Google Sheets
  Nota: En un entorno real, usar√≠as credenciales de service account
  """
  print("Configurando conexi√≥n con Google Sheets...")
# Para este ejercicio, simularemos la conexi√≥n
# En producci√≥n, usar√≠as:
# scope =['https://spreadsheets.google.com/feeds',
#'https://www.googleapis.com/auth/drive']
# creds = Credentials.from_service_account_file('credentials.json', scopes=scope)
# client = gspread.authorize(creds)
  print("‚úÖConfiguraci√≥n de Google Sheets completada")
  return True
def crear_datos_dashboard():
  """
  Crea los datos que se enviar√°n al dashboard
  """
  # Simular datos de m√©tricas del modelo
  metricas_modelo = {'fecha_actualizacion': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
  'accuracy_modelo': 0.89,
  'mae': 1250.50,
  'r2_score': 0.85,
  'mape': 8.5,
  'predicciones_procesadas': 1250,
  'tiempo_ejecucion_minutos': 12.5,
  'version_modelo': 'v2.3',
  'estado': 'Activo'
  }

  # Simular predicciones semanales por tienda
  predicciones_semanales = \
  []
  tiendas = [f"Tienda_{i:02d}" for i in range(1, 21)]
  fecha_base = datetime.now()
  for i, tienda in enumerate(tiendas):
    prediccion = {
    'tienda_id': tienda,
    'fecha_prediccion': (fecha_base + timedelta(days=7)).strftime('%Y-%m-%d'),
    'ventas_predichas': np.random.normal(15000, 3000),
    'ventas_reales_semana_anterior': np.random.normal(14500, 2800),
    'diferencia_vs_anterior': 0,
    'confianza_prediccion': np.random.uniform(0.80, 0.95),
                   'promocion_activa': np.random.choice(['S√≠', 'No']),
    'categoria_performance': ''
    }
    # Calcular diferencia
    prediccion['diferencia_vs_anterior'] = prediccion['ventas_predichas']-prediccion['ventas_reales_semana_anterior']

    # Categorizar performance
    if prediccion['diferencia_vs_anterior'] > 1000:
      prediccion['categoria_performance'] = 'Alto Crecimiento'
    elif prediccion['diferencia_vs_anterior'] > 0:
      prediccion['categoria_performance'] = 'Crecimiento Moderado'
    elif prediccion['diferencia_vs_anterior'] >-1000:
      prediccion['categoria_performance'] = 'Estable'
    else:
      prediccion['categoria_performance'] = 'Declive'
    predicciones_semanales.append(prediccion)
  # Simular performance por tienda
  performance_tiendas = []
  for tienda in tiendas:
    performance = {
    'tienda_id': tienda,
    'ventas_ytd': np.random.normal(750000, 150000),
    'objetivo_ytd': np.random.normal(800000, 100000),
    'cumplimiento_objetivo': 0,
    'accuracy_predicciones_l4w': np.random.uniform(0.75, 0.95),
    'tendencia_ventas': np.random.choice(['Creciente', 'Estable', 'Decreciente']),
    'riesgo_nivel': ''
    }

    # Calcular cumplimiento
    performance['cumplimiento_objetivo'] = (performance['ventas_ytd'] / performance['objetivo_ytd']) * 100
    # Determinar nivel de riesgo
    if performance['cumplimiento_objetivo'] < 80:
      performance['riesgo_nivel'] = 'Alto'
    elif performance['cumplimiento_objetivo'] < 95:
      performance['riesgo_nivel'] = 'Medio'
    else:
      performance['riesgo_nivel'] = 'Bajo'
    performance_tiendas.append(performance)
  # Generar alertas autom√°ticas
  alertas = []
  for tienda_data in performance_tiendas:
    if tienda_data['riesgo_nivel'] == 'Alto':
      alertas.append({
      'fecha': datetime.now().strftime('%Y-%m-%d'),
      'tipo_alerta': 'Riesgo Alto',
      'tienda_id': tienda_data['tienda_id'],
      'descripcion': f"Cumplimiento de objetivo: {tienda_data['cumplimiento_objetivo']:.1f}%",
      'accion_recomendada': 'Revisar estrategia comercial',
      'prioridad': 'Alta',
      'estado': 'Activa'
      })

  # Agregar alertas de modelo
  if metricas_modelo['accuracy_modelo'] < 0.85:
    alertas.append({
    'fecha': datetime.now().strftime('%Y-%m-%d'),
    'tipo_alerta': 'Performance Modelo',
    'tienda_id': 'Todas',
    'descripcion': f"Accuracy del modelo: {metricas_modelo['accuracy_modelo']:.2f}",
    'accion_recomendada': 'Considerar reentrenamiento',
    'prioridad': 'Media',
    'estado': 'Activa'
    })
  return {
  'metricas_modelo': metricas_modelo,
  'predicciones_semanales': predicciones_semanales,
  'performance_tiendas': performance_tiendas,
  'alertas': alertas
  }
# Generar datos para el dashboard
datos_dashboard = crear_datos_dashboard()
print("‚úÖDatos del dashboard generados")

"""#### üí°Nota:
En un entorno real, estos datos vendr√≠an directamente de tu pipeline ML automatizado.

#### Paso 2: Simulaci√≥n de env√≠o a Google Sheets
"""

def simular_envio_google_sheets(datos):
  """
  Simula el env√≠o de datos a Google Sheets
  En producci√≥n, esto escribir√≠a realmente a las hojas
  """
  print("üì§Simulando env√≠o de datos a Google Sheets...")
  # Simular escritura de m√©tricas del modelo
  print(f"‚úÖM√©tricas del modelo actualizadas: {datos['metricas_modelo']['fecha_actualizacion']}")
  print(f"‚úÖ{len(datos['predicciones_semanales'])} predicciones semanales enviadas")
  print(f"‚úÖPerformance de {len(datos['performance_tiendas'])} tiendas actualizada")
  print(f"‚úÖ{len(datos['alertas'])} alertas generadas")
  # Crear archivos CSV para simular los datos que ir√≠an a Sheets
  import pandas as pd
  # Guardar m√©tricas del modelo
  df_metricas = pd.DataFrame([datos['metricas_modelo']])
  df_metricas.to_csv('dashboard_metricas_modelo.csv', index=False)
  # Guardar predicciones semanales
  df_predicciones = pd.DataFrame(datos['predicciones_semanales'])
  df_predicciones.to_csv('dashboard_predicciones_semanales.csv', index=False)
  # Guardar performance de tiendas
  df_performance = pd.DataFrame(datos['performance_tiendas'])
  df_performance.to_csv('dashboard_performance_tiendas.csv', index=False)
  # Guardar alertas
  df_alertas = pd.DataFrame(datos['alertas'])
  df_alertas.to_csv('dashboard_alertas.csv', index=False)
  print("‚úÖArchivos CSV generados para importar a Google Sheets")
  return True
# Simular env√≠o
envio_exitoso = simular_envio_google_sheets(datos_dashboard)

"""### Paso 3: Estructura del Dashboard en Google Data Studio

Ahora crear√°s la estructura del dashboard. Sigue estos pasos:

"""

def generar_especificaciones_dashboard():
  """
  Genera las especificaciones detalladas para crear el dashboard
  """
  especificaciones = {
  'titulo': 'RetailMax ML Analytics-Dashboard Ejecutivo',
  'dimensiones': '1920x1080',
  'tema': 'Corporativo Azul',
  'paginas': [
  {
  'nombre': 'Resumen Ejecutivo',
  'componentes': [
  {
  'tipo': 'Scorecard',
  'titulo': 'Accuracy del Modelo',
  'metrica': 'accuracy_modelo',
  'formato': 'Porcentaje',
  'color_threshold': {'verde': '>85%', 'amarillo': '80-85%',
  'rojo': '<80%'}
  },
  {
  'tipo': 'Scorecard',
  'titulo': 'Total Predicciones',
  'metrica': 'predicciones_procesadas',
  'formato': 'N√∫mero'
  },
  {
  'tipo': 'Scorecard',
  'titulo': 'Error Promedio',
  'metrica': 'mae',
  'formato': 'Moneda'
  },
  {
  'tipo': 'Gr√°fico de Barras',
  'titulo': 'Predicciones por Categor√≠a de Performance',
  'dimension': 'categoria_performance',
  'metrica': 'count(tienda_id)',
  'orientacion': 'horizontal'
  },
  {
  'tipo': 'Tabla',
  'titulo': 'Top 10 Tiendas-Predicciones M√°s Altas',
  'dimensiones': ['tienda_id', 'ventas_predichas', 'confianza_prediccion'],
  'orden': 'ventas_predichas DESC',
  'limite': 10
  }
  ]
  },
         {
  'nombre': 'Performance por Tienda',
  'componentes': [
  {
  'tipo': 'Mapa de Calor',
  'titulo': 'Cumplimiento de Objetivos por Tienda',
  'dimension': 'tienda_id',
  'metrica': 'cumplimiento_objetivo',
  'escala_color': 'Rojo-Amarillo-Verde'
  },
  {
  'tipo': 'Gr√°fico de Dispersi√≥n',
  'titulo': 'Ventas YTD vs Objetivo',
  'eje_x': 'objetivo_ytd',
  'eje_y': 'ventas_ytd',
  'color': 'riesgo_nivel'
  },
  {
  'tipo': 'Gr√°fico de Barras',
  'titulo': 'Distribuci√≥n de Niveles de Riesgo',
  'dimension': 'riesgo_nivel',
  'metrica': 'count(tienda_id)'
  }
  ]
  },
  {
  'nombre': 'Alertas y Monitoreo',
  'componentes': [
  {
  'tipo': 'Tabla de Alertas',
  'titulo': 'Alertas Activas',
  'filtro': 'estado = "Activa"',
  'dimensiones': ['fecha', 'tipo_alerta', 'tienda_id', 'descripcion', 'prioridad'],
  'formato_condicional': {'Alta': 'rojo', 'Media': 'amarillo'
  , 'Baja': 'verde'}
  },
  {
  'tipo': 'Gr√°fico de L√≠neas',
  'titulo': 'Evoluci√≥n de Accuracy del Modelo',
  'dimension': 'fecha_actualizacion',
  'metrica': 'accuracy_modelo',
  'periodo': '√öltimos 30 d√≠as'
  }
  ]
  }
  ],
  'filtros_globales': [
  'Rango de fechas',
  'Tienda espec√≠fica'
                        'Nivel de riesgo'
  ],
  'actualizacion': 'Autom√°tica cada hora'
  }
  return especificaciones
# Generar especificaciones
specs_dashboard = generar_especificaciones_dashboard()
# Mostrar especificaciones
print("üìäESPECIFICACIONES DEL DASHBOARD EJECUTIVO")
print("="*50)
print(f"T√≠tulo: {specs_dashboard['titulo']}")
print(f"Dimensiones: {specs_dashboard['dimensiones']}")
print(f"Tema: {specs_dashboard['tema']}")
print(f"Actualizaci√≥n: {specs_dashboard['actualizacion']}")
print("\nP√°ginas del Dashboard:")
for i, pagina in enumerate(specs_dashboard['paginas'], 1):
  print(f"\n{i}. {pagina['nombre']}")
  for j, componente in enumerate(pagina['componentes'], 1):
    print(f" {i}.{j} {componente['tipo']}: {componente['titulo']}")

"""#### Paso 4: Creaci√≥n de M√©tricas Calculadas

"""

def generar_metricas_calculadas():
  """
  Define las m√©tricas calculadas que se usar√°n en Data Studio
  """
  metricas_calculadas = {
  'Cumplimiento_Objetivo_Pct': {
  'formula': '(Ventas_YTD / Objetivo_YTD) * 100',
  'tipo': 'Porcentaje',
  'descripcion': 'Porcentaje de cumplimiento del objetivo anual'
  },
  'Diferencia_Prediccion_Pct': {
  'formula': '((Ventas_Predichas-Ventas_Reales_Anterior) / Ventas_Reales_Anterior) * 100',
  'tipo': 'Porcentaje',
  'descripcion': 'Cambio porcentual vs semana anterior'
  },
  'Score_Confianza_Ponderado': {
  'formula': 'Confianza_Prediccion * (Ventas_Predichas / AVG(Ventas_Predichas))',
  'tipo': 'N√∫mero',
                               'descripcion': 'Score de confianza ponderado por volumen de ventas'
  },
  'Alertas_Criticas': {
  'formula': 'COUNT_DISTINCT(CASE WHEN Prioridad = "Alta" THEN Tienda_IDEND)',
  'tipo': 'N√∫mero',
  'descripcion': 'N√∫mero de tiendas con alertas cr√≠ticas'
  },
  'Accuracy_Trend': {
  'formula': 'AVG(Accuracy_Modelo) OVER (ORDER BY Fecha_Actualizacion ROWS 6 PRECEDING)',
  'tipo': 'Porcentaje',
  'descripcion': 'Tendencia de accuracy en √∫ltimas 7 actualizaciones'
  }
  }
  print("üßÆM√âTRICAS CALCULADAS PARA DATA STUDIO")
  print("="*50)
  for nombre, metrica in metricas_calculadas.items():
    print(f"üìä\n{nombre}")
    print(f" F√≥rmula: {metrica['formula']}")
    print(f" Tipo: {metrica['tipo']}")
    print(f" Descripci√≥n: {metrica['descripcion']}")
  return metricas_calculadas
# Generar m√©tricas calculadas
metricas_calc = generar_metricas_calculadas()

"""#### Paso 5: Configuraci√≥n de Alertas Autom√°ticas

"""

def configurar_alertas_automaticas():
  """
  Configura las reglas de alertas autom√°ticas
  """
  reglas_alertas = {
  'Accuracy_Modelo_Bajo': {
  'condicion': 'accuracy_modelo < 0.85',
  'mensaje': 'Accuracy del modelo por debajo del threshold m√≠nimo',
  'accion': 'Notificar al equipo de Data Science',
  'frecuencia': 'Inmediata',
  'destinatarios': ['data-team@retailmax.com','cto@retailmax.com']
  },
  'Tienda_Alto_Riesgo': {
  'condicion': 'cumplimiento_objetivo < 80 AND riesgo_nivel = "Alto"',
  'mensaje': 'Tienda con alto riesgo de no cumplir objetivos',
  'accion': 'Notificar al gerente regional',
  'frecuencia': 'Diaria',
                        'destinatarios': ['regional-managers@retailmax.com']
  },
  'Prediccion_Anomala': {
  'condicion': 'ABS(diferencia_vs_anterior) > 5000',
  'mensaje': 'Predicci√≥n con cambio significativo vs per√≠odo anterior',
  'accion': 'Revisar datos de entrada y modelo',
  'frecuencia': 'Semanal',
  'destinatarios': ['analytics-team@retailmax.com']
  },
  'Error_Prediccion_Alto': {
  'condicion': 'mae > 2000',
  'mensaje': 'Error de predicci√≥n por encima del threshold aceptable',
  'accion': 'Considerar reentrenamiento del modelo',
  'frecuencia': 'Semanal',
  'destinatarios': ['data-team@retailmax.com']
  }
  }
  print("üö®CONFIGURACI√ìN DE ALERTAS AUTOM√ÅTICAS")
  print("="*50)
  for nombre, regla in reglas_alertas.items():
    print(f"\n‚ö†Ô∏è{nombre}")
    print(f" Condici√≥n: {regla['condicion']}")
    print(f" Mensaje: {regla['mensaje']}")
    print(f" Acci√≥n: {regla['accion']}")
    print(f" Frecuencia: {regla['frecuencia']}")
    print(f" Destinatarios: {', '.join(regla['destinatarios'])}")
  return reglas_alertas
# Configurar alertas
alertas_config = configurar_alertas_automaticas()

"""#### Paso 6: Gu√≠a de Implementaci√≥n en Google Data Studio

"""

def generar_guia_implementacion():
  """
  Genera una gu√≠a paso a paso para implementar el dashboard
  """
  guia = """
#üìã
GU√çA DE IMPLEMENTACI√ìN-GOOGLE DATA STUDIO
================================================
PASO 1: PREPARAR DATOS EN GOOGLE SHEETS
---------------------------------------
1. Crear un nuevo Google Sheets llamado "RetailMax_ML_Dashboard_Data"
2. Crear 4 pesta√±as:
-
Metricas_Modelo
-
Predicciones_Semanales
-
Performance_Tiendas
-
Alertas
3. Importar los archivos CSV generados en cada pesta√±a correspondiente
4. Configurar formato de fechas y n√∫meros seg√∫n sea necesario
PASO 2: CREAR DASHBOARD EN DATA STUDIO
-------------------------------------
1. Ir a datastudio.google.com
2. Crear un nuevo informe
3. Conectar como fuente de datos el Google Sheets creado
4. Seleccionar cada pesta√±a como tabla separada
PASO 3: CONFIGURAR P√ÅGINA "RESUMEN EJECUTIVO"
-------------------------------------------
1. Agregar t√≠tulo: "RetailMax ML Analytics-Dashboard Ejecutivo"
2. Insertar 3 Scorecards:
-
Accuracy del Modelo (accuracy_modelo, formato %)
-
Total Predicciones (predicciones_procesadas, formato #)
-
Error Promedio (mae, formato $)
3. Agregar gr√°fico de barras:
-
Dimensi√≥n: categoria_performance
-
M√©trica: COUNT(tienda_id)
-
T√≠tulo: "Predicciones
por Categor√≠a de Performance"
4. Insertar tabla:
-
Dimensiones: tienda_id, ventas_predichas, confianza_prediccion
-
Ordenar por: ventas_predichas DESC
-
Mostrar: 10 filas
PASO 4: CONFIGURAR P√ÅGINA "PERFORMANCE POR TIENDA"
----------------------------------------------
1. Crear nueva p√°gina
2. Agregar gr√°fico de barras (mapa de calor simulado):
-
Dimensi√≥n: tienda_id
-
M√©trica: cumplimiento_objetivo
-
Configurar colores condicionales
3. Insertar gr√°fico de dispersi√≥n:
-
Eje X: objetivo_ytd
-
Eje Y: ventas_ytd
-
Color: riesgo_nivel
4. Agregar gr√°fico de barras:
-
Dimensi√≥n: riesgo_nivel
-
M√©trica: COUNT(tienda_id)
PASO 5: CONFIGURAR P√ÅGINA "ALERTAS Y MONITOREO"
---------------------------------------------
1. Crear nueva p√°gina
2. Insertar tabla de alertas:
-
Filtrar por: estado = "Activa"
-
Dimensiones: fecha, tipo_alerta, tienda_id, descripcion, prioridad
-
Aplicar formato condicional por prioridad
3. Agregar gr√°fico de l√≠neas (simulado con datos hist√≥ricos):
-
Dimensi√≥n: fecha_actualizacion
-
M√©trica: accuracy_modelo
PASO 6: CONFIGURAR FILTROS
Y CONTROLES
------------------------------------
1. Agregar control de rango de fechas
2. Insertar filtro desplegable para tienda_id
3. Agregar filtro para riesgo_nivel
4. Configurar filtros como globales para todas las p√°ginas
PASO 7: CONFIGURAR ACTUALIZACI√ìN AUTOM√ÅTICA
-----------------------------------------
1. En Google Sheets, configurar Google Apps Script para actualizaci√≥n
2. En Data Studio, configurar actualizaci√≥n de datos cada hora
3. Configurar notifi
caciones por email para alertas cr√≠ticas
PASO 8: COMPARTIR Y CONFIGURAR PERMISOS
-------------------------------------
1. Configurar permisos de visualizaci√≥n para ejecutivos
2. Dar permisos de edici√≥n al equipo de analytics
3. Crear enlace compartible para acceso r√°pido
4. Configurar embedding si es necesario para intranet
"""
  print(guia)
  # Crear archivo con la gu√≠a
  with open('guia_implementacion_dashboard.txt', 'w', encoding='utf-8') as f:
    f.write(guia)
  print("\n‚úÖGu√≠a de implementaci√≥n guardada en 'guia_implementacion_dashboard.txt'")
# Generar gu√≠a
generar_guia_implementacion()

"""#### Paso 7: Validaci√≥n y Testing del Dashboard

"""

def crear_checklist_validacion():
  """
  Crea un checklist para validar el dashboard
  """
  checklist = {
  'Funcionalidad': [
  '‚úì Todos los gr√°ficos cargan correctamente',
  '‚úì Los filtros funcionan en todas las p√°ginas',
  '‚úì Las m√©tricas calculadas muestran valores correctos',
  '‚úì Los colores condicionales se aplican apropiadamente',
  '‚úì La navegaci√≥n entre p√°ginas es fluida'
  ],
  'Datos': [
  '‚úì Los datos se actualizan autom√°ticamente',
  '‚úì No hay valores nulos o errores en las visualizaciones',
  '‚úì Las fechas se muestran en formato correcto',
  '‚úì Los n√∫meros tienen el formato apropiado (moneda, porcentaje)',
  '‚úì Los totales y subtotales son correctos'
  ],
  'Dise√±o': [
  '‚úì El dashboard es responsive en diferentes tama√±os de pantalla',
  '‚úì Los colores son consistentes con la marca corporativa',
  '‚úì Los t√≠tulos y etiquetas son claros y descriptivos',
  '‚úì Hay suficiente espacio en blanco para legibilidad',
  '‚úì La jerarqu√≠a visual gu√≠a la atenci√≥n correctamente'
  ],
  'Performance': [
  '‚úì El dashboard carga en menos de 10 segundos',
  '‚úì Los filtros responden r√°pidamente',
  '‚úì No hay timeouts en la carga de datos',
  '‚úì El dashboard funciona en diferentes navegadores',
  '‚úì La experiencia m√≥vil es aceptable'
  ],
  'Negocio': [
  '‚úì Las m√©tricas mostradas son relevantes para ejecutivos',
  '‚úì Los insights son accionables',
  '‚úì Las alertas se generan apropiadamente',
  '‚úì El dashboard responde preguntas clave del negocio',
  '‚úì Los usuarios pueden encontrar la informaci√≥n que necesitan'
  ]
  }
  print("‚úÖCHECKLIST DE VALIDACI√ìN DEL DASHBOARD")
  print("="*50)
  for categoria, items in checklist.items():
    print(f"\nüìã{categoria.upper()}")
    for item in items:
      print(f" {item}")
  return checklist
# Crear checklist
checklist_validacion = crear_checklist_validacion()

"""## 1.7 Sistema Completo de ML en Producci√≥n

**Objetivo:**
Integrar todos los componentes desarrollados en un sistema completo de ML en
producci√≥n

### 1.7.1 Contexto
RetailMax quiere implementar el sistema completo de predicci√≥n de ventas en producci√≥n.
Necesitas crear un flujo end-to-end que incluya automatizaci√≥n, monitoreo, alertas, y m√∫ltiples
interfaces para diferentes tipos de usuarios.

### 1.7.2 Instrucciones Paso a Paso

#### Paso 1: Arquitectura del Sistema Integrado
"""

# Configuraci√≥n del sistema integrado
import os
import json
import logging
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
import plotly.express as px
import plotly.graph_objects as go
import pickle
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import warnings
warnings.filterwarnings('ignore')
# Configuraci√≥n global del sistema
SISTEMA_CONFIG = {
    'nombre_proyecto': 'RetailMax_ML_Production_System',
    'version': '1.0.0',
    'ambiente': 'production',
    'fecha_deployment': datetime.now().strftime('%Y-%m-%d'),
    'componentes': {
        'pipeline_ml': True,
        'reportes_automaticos': True,
        'dashboard_streamlit': True,
        'dashboard_ejecutivo': True,
        'sistema_alertas': True,
        'monitoreo': True
    },
    'configuracion_alertas': {
        'email_smtp': 'smtp.gmail.com',
        'email_puerto': 587,
        'email_remitente':'sistema@retailmax.com',
        'destinatarios_criticos':['cto@retailmax.com','data-team@retailmax.com'],
        'destinatarios_operativos':['analytics@retailmax.com']
    },
    'thresholds': {
        'accuracy_minima': 0.85,
        'mae_maxima': 5000, # Ajustado para ser m√°s permisivo
        'r2_minimo': 0.01, # Ajustado para ser m√°s permisivo
        'mape_maxima': 50.0, # A√±adido MAPE al config
        'confianza_minima': 0.75
    }
}

def inicializar_sistema():
  """
  Inicializa el sistema completo con logging y configuraci√≥n
  """
  # Configurar logging avanzado
  logging.basicConfig(
      level=logging.INFO,
      format='%(asctime)s-%(name)s-%(levelname)s-%(message)s',
      handlers=[
          logging.FileHandler(f'sistema_ml_production_{datetime.now().strftime("%Y%m%d")}.log'),
          logging.StreamHandler()
      ]
  )
  logger = logging.getLogger('RetailMaxML')
  logger.info("="*60)
  logger.info("INICIALIZANDO SISTEMA MLRETAILMAX")
  logger.info(f"Versi√≥n: {SISTEMA_CONFIG['version']}")
  logger.info(f"Ambiente: {SISTEMA_CONFIG['ambiente']}")
  logger.info(f"Fecha Deployment: {SISTEMA_CONFIG['fecha_deployment']}")
  logger.info("="*60)
  # Verificar componentes
  componentes_activos = [k for k, v in SISTEMA_CONFIG['componentes'].items() if v]
  logger.info(f"Componentes activos: {', '.join(componentes_activos)}")
  return logger
# Inicializar sistema
logger = inicializar_sistema()

"""#### üí° Nota:
Un sistema de logging robusto es crucial en producci√≥n para diagnosticar problemas y
monitorear performance.

#### Paso 2: Clase Principal del Sistema ML
"""

class SistemaMLRetailMax:
    """
    Clase principal que orquesta todo el sistema ML
    """
    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger('RetailMaxML.Sistema')
        self.modelo = None
        self.datos_historicos = None
        self.metricas_actuales = {}
        self.estado_sistema = 'Inicializando'
        self.logger.info("Sistema ML inicializado")

    def cargar_datos(self, ruta_datos=None):
        """
        Carga y valida los datos del sistema
        """
        try:
            self.logger.info("Cargando datos del sistema...")
            if ruta_datos is None:
                # Generar datos sint√©ticos para demostraci√≥n
                self.datos_historicos = self._generar_datos_sinteticos()
            else:
                self.datos_historicos = pd.read_csv(ruta_datos)
            # Validar datos
            self._validar_datos()
            self.logger.info(f"Datos cargados exitosamente: {self.datos_historicos.shape}")
            return True
        except Exception as e:
            self.logger.error(f"Error cargando datos: {e}")
            return False

    def _generar_datos_sinteticos(self):
        """
        Genera datos sint√©ticos para demostraci√≥n
        """
        np.random.seed(42)
        #
        # Generar datos m√°s realistas
        fechas = pd.date_range(start='2023-01-01', end='2024-03-15', freq='W')
        tiendas = [f"Tienda_{i:02d}" for i in range(1, 51)] # 50 tiendas
        data = []
        for tienda in tiendas:
            # Cada tienda tiene caracter√≠sticas base diferentes
            base_ventas = np.random.normal(15000, 3000)
            estacionalidad = np.random.uniform(0.8, 1.2)
            for i, fecha in enumerate(fechas):
                # Simular estacionalidad
                factor_estacional = 1 + 0.3 * np.sin(2 * np.pi * fecha.dayofyear /365)
                # Simular tendencia
                factor_tendencia = 1 + (i / len(fechas)) * 0.1
                # Simular efectos de promociones
                promocion = np.random.choice([0, 1], p=[0.75, 0.25])
                factor_promocion = 1.15 if promocion else 1.0
                ventas = base_ventas * factor_estacional * factor_tendencia * factor_promocion
                ventas += np.random.normal(0, ventas * 0.1) # Ruido

                data.append({
                    'fecha': fecha,
                    'tienda_id': tienda,
                    'ventas_semanales': max(0, ventas),
                    'promocion_activa': promocion,
                    'inventario_inicial': np.random.normal(50000, 10000),
                    'temperatura_promedio': 20 +15 * np.sin(2 * np.pi * fecha.dayofyear / 365) + np.random.normal(0, 3),
                    'a√±o': fecha.year,
                    'mes': fecha.month,
                    'semana': fecha.isocalendar().week,
                    'dia_semana': fecha.dayofweek
                })
        return pd.DataFrame(data)

    def _validar_datos(self):
        """
        Valida la calidad de los datos
        """
        validaciones = {
            'filas_vacias': self.datos_historicos.isnull().sum().sum(),
            'duplicados': self.datos_historicos.duplicated().sum(),
            'fechas_invalidas': 0, # Simplificado para demo
            'valores_negativos': (self.datos_historicos['ventas_semanales'] < 0).sum()}

        for validacion, count in validaciones.items():
            if count > 0:
                self.logger.warning(f"‚ö†Ô∏è {validacion}: {count} problemas encontrados.")

    def entrenar_modelo(self):
        """
        Entrena el modelo ML con los datos cargados
        """
        try:
            self.logger.info("Iniciando entrenamiento del modelo...")
            # Preparar features
            feature_columns = ['promocion_activa', 'inventario_inicial', 'temperatura_promedio',
                               'a√±o', 'mes', 'semana', 'dia_semana']
            X = self.datos_historicos[feature_columns]
            y = self.datos_historicos['ventas_semanales']

            # Dividir datos temporalmente (m√°s realista para series de tiempo)
            fecha_corte = self.datos_historicos['fecha'].quantile(0.8)
            mask_train = self.datos_historicos['fecha'] <= fecha_corte
            X_train, X_test = X[mask_train], X[~mask_train]
            y_train, y_test = y[mask_train], y[~mask_train]

            # Entrenar modelo
            self.modelo = RandomForestRegressor(
                n_estimators=200,
                max_depth=15,
                random_state=42,
                n_jobs=-1)
            self.modelo.fit(X_train, y_train)

            # Evaluar modelo
            y_pred = self.modelo.predict(X_test)
            self.metricas_actuales = {
                'mae': mean_absolute_error(y_test, y_pred),
                'r2': r2_score(y_test, y_pred),
                'mape': np.mean(np.abs((y_test-y_pred) / y_test)) * 100,
                'accuracy_10pct': np.mean(np.abs((y_test-y_pred) / y_test) <= 0.1)*100,
                'fecha_entrenamiento': datetime.now(),
                'samples_entrenamiento': len(X_train),
                'samples_test': len(X_test)
            }

            self.logger.info("Modelo entrenado exitosamente")
            self.logger.info(f"MAE: {self.metricas_actuales['mae']:.2f}")
            self.logger.info(f"R¬≤: {self.metricas_actuales['r2']:.3f}")
            self.logger.info(f"MAPE: {self.metricas_actuales['mape']:.1f}%")
            self.estado_sistema = 'Modelo Entrenado'
            return True
        except Exception as e:
            self.logger.error(f"Error entrenando modelo: {e}")
            self.estado_sistema = 'Error'
            return False

    def validar_modelo(self):
        """
        Valida que el modelo cumple con los thresholds de calidad
        """
        self.logger.info("Validando calidad del modelo...")

        current_r2 = self.metricas_actuales.get('r2', 0.0)
        threshold_r2 = self.config['thresholds']['r2_minimo']
        current_mae = self.metricas_actuales.get('mae', float('inf'))
        threshold_mae = self.config['thresholds']['mae_maxima']
        current_mape = self.metricas_actuales.get('mape', float('inf'))
        threshold_mape = self.config['thresholds']['mape_maxima'] # Referenciar desde config

        print(f"DEBUG: Current R2: {current_r2:.3f}, Threshold R2: {threshold_r2:.3f}")
        print(f"DEBUG: Current MAE: {current_mae:.2f}, Threshold MAE: {threshold_mae:.2f}")
        print(f"DEBUG: Current MAPE: {current_mape:.2f}, Threshold MAPE: {threshold_mape:.2f}")

        validaciones = {
            'accuracy_ok': current_r2 >= threshold_r2,
            'mae_ok': current_mae <= threshold_mae,
            'mape_ok': current_mape <= threshold_mape
        }
        todas_ok = all(validaciones.values())

        for validacion, resultado in validaciones.items():
            status = "‚úìPASS" if resultado else "‚úóFAIL"
            self.logger.info(f"Validaci√≥n {validacion}: {status}")
            print(f"DEBUG: Validaci√≥n {validacion}: {status}")

        if todas_ok:
            self.logger.info("‚úÖModelo aprobado para producci√≥n")
            self.estado_sistema = 'Modelo Validado'
        else:
            self.logger.warning("‚ö†Ô∏èModelo no cumple con todos los criterios")
            self.estado_sistema = 'Modelo Rechazado'
        return todas_ok

    def generar_predicciones_batch(self, datos_nuevos=None):
        """
        Genera predicciones en lote para todas las tiendas
        """
        try:
            self.logger.info("Generando predicciones en lote...")
            if datos_nuevos is None:
                # Simular datos para pr√≥xima semana
                datos_nuevos = self._simular_datos_proxima_semana()
            # Hacer predicciones
            feature_columns = ['promocion_activa', 'inventario_inicial', 'temperatura_promedio','a√±o', 'mes', 'semana', 'dia_semana']
            X_pred = datos_nuevos[feature_columns]
            predicciones = self.modelo.predict(X_pred)

            # Agregar predicciones al DataFrame
            datos_nuevos['ventas_predichas'] = predicciones
            datos_nuevos['fecha_prediccion'] = datetime.now()
            datos_nuevos['version_modelo'] = self.config['version']
            self.logger.info(f"Predicciones generadas para {len(datos_nuevos)} tiendas")
            return datos_nuevos
        except Exception as e:
            self.logger.error(f"Error generando predicciones: {e}")
            return None

    def _simular_datos_proxima_semana(self):
        """
        Simula datos para la pr√≥xima semana
        """
        fecha_proxima = datetime.now() + timedelta(days=7)
        tiendas = self.datos_historicos['tienda_id'].unique()
        datos_proxima_semana = []
        for tienda in tiendas:
            datos_proxima_semana.append({
                'tienda_id': tienda,
                'fecha': fecha_proxima,
                'promocion_activa': np.random.choice([0, 1], p=[0.7, 0.3]),
                'inventario_inicial': np.random.normal(50000, 10000),
                'temperatura_promedio': np.random.normal(20, 8),
                'a√±o': fecha_proxima.year,
                'mes': fecha_proxima.month,
                'semana': fecha_proxima.isocalendar().week,
                'dia_semana': fecha_proxima.dayofweek
            })
        return pd.DataFrame(datos_proxima_semana)

    def monitorear_sistema(self):
        """
        Monitorea el estado general del sistema
        """
        self.logger.info("Ejecutando monitoreo del sistema...")
        estado_monitoreo = {
            'timestamp': datetime.now(),
            'estado_general': self.estado_sistema,
            'modelo_cargado': self.modelo is not None,
            'datos_disponibles': self.datos_historicos is not None,
            'metricas_actuales': self.metricas_actuales,
            'alertas_activas': []
        }
        # Verificar alertas
        if self.metricas_actuales:
            if self.metricas_actuales['r2'] < self.config['thresholds']['r2_minimo']:
                estado_monitoreo['alertas_activas'].append({
                    'tipo': 'Performance',
                    'mensaje': f"R¬≤ por debajo del m√≠nimo: {self.metricas_actuales['r2']:.3f}",
                    'severidad': 'Alta'
                })
            if self.metricas_actuales['mae'] > self.config['thresholds']['mae_maxima']:
                estado_monitoreo['alertas_activas'].append({
                    'tipo': 'Accuracy',
                    'mensaje': f"MAE por encima del m√°ximo: {self.metricas_actuales ['mae']:.2f}",
                    'severidad': 'Media'
                })
        self.logger.info(f"Monitoreo completado. Alertas activas: {len(estado_monitoreo['alertas_activas'])}")
        return estado_monitoreo

# Crear instancia del sistema
sistema_ml = SistemaMLRetailMax(SISTEMA_CONFIG)

"""#### ¬øPor qu√© usar una clase?
Encapsula toda la l√≥gica del sistema, mantiene el estado, y facilita el
mantenimiento y testing del c√≥digo.

#### Paso 3: Orquestador de Flujo Completo
"""

class OrquestadorProduccion:
  """
  Orquesta la ejecuci√≥n completa del sistema en producci√≥n
  """
  def __init__(self, sistema_ml):
    self.sistema = sistema_ml
    self.logger = logging.getLogger('RetailMaxML.Orquestador')
    self.resultados_ejecucion = {}

  def ejecutar_flujo_completo(self):
    """
    Ejecuta el flujo completo end-to-end
    """
    self.logger.info("üöÄINICIANDO FLUJO COMPLETO DE PRODUCCI√ìN")
    flujo_pasos = [
    ('Cargar Datos', self.sistema.cargar_datos),
    ('Entrenar Modelo', self.sistema.entrenar_modelo),
    ('Validar Modelo', self.sistema.validar_modelo),
    ('Generar Predicciones', self._paso_predicciones),
    ('Generar Reportes', self._paso_reportes),
    ('Actualizar Dashboards', self._paso_dashboards),
    ('Enviar Notificaciones', self._paso_notificaciones),
    ('Monitorear Sistema', self._paso_monitoreo)
    ]
    resultados = {}
    for nombre_paso, funcion_paso in flujo_pasos:
      self.logger.info(f"üìãEjecutando: {nombre_paso}")
      try:
        inicio = datetime.now()
        resultado = funcion_paso()
        duracion = (datetime.now()
        -
        inicio).total_seconds()
        resultados[nombre_paso] = {
        'exito': resultado,
        'duracion_segundos': duracion,
        'timestamp': inicio
        }
        if resultado:
          self.logger.info(f"‚úÖ{nombre_paso} completado en {duracion:.1f}s")
        else:
          self.logger.error(f"‚ùå{nombre_paso} fall√≥")
          break
      except Exception as e:
        self.logger.error(f"üí•Error en {nombre_paso}: {e}")
        resultados[nombre_paso] = {
        'exito': False,
        'error': str(e),
        'timestamp': datetime.now()
        }
        break
    self.resultados_ejecucion = resultados
    self._generar_reporte_ejecucion()
    return resultados

  def _paso_predicciones(self):
    """
    Paso de generaci√≥n de predicciones
    """
    predicciones = self.sistema.generar_predicciones_batch()
    if predicciones is not None:
      # Guardar predicciones
      archivo_predicciones = f"predicciones_batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
      predicciones.to_csv(archivo_predicciones, index=False)
      self.logger.info(f"Predicciones guardadas en: {archivo_predicciones}")
      return True
    return False

  def _paso_reportes(self):
    """
    Paso de generaci√≥n de reportes autom√°ticos
    """
    try:
      # Simular generaci√≥n de reportes
      reportes_generados = [
      f"reporte_performance_{datetime.now().strftime('%Y%m%d')}.html",
      f"reporte_predicciones_{datetime.now().strftime('%Y%m%d')}.pdf",
      f"reporte_alertas_{datetime.now().strftime('%Y%m%d')}.xlsx"
      ]
      for reporte in reportes_generados:
        # Simular creaci√≥n de archivo
        with open(reporte, 'w') as f:
          f.write(f"Reporte generado autom√°ticamente-{datetime.now()}")
        self.logger.info(f"Reporte generado: {reporte}")
      return True
    except Exception as e:
      self.logger.error(f"Error generando reportes: {e}")
      return False

  def _paso_dashboards(self):
    """
    Paso de actualizaci√≥n d
    e dashboards
    """
    try:
      # Simular actualizaci√≥n de dashboards
      dashboards = [
      'Streamlit App',
      'Google Data Studio',
      'Dashboard Ejecutivo'
      ]
      for dashboard in dashboards:
        # Simular actualizaci√≥n
        self.logger.info(f"Actualizando {dashboard}...")
      # En producci√≥n real, aqu√≠ se actualizar√≠an los datos de los dashbo
      # ards
      self.logger.info("Todos los dashboards actualizados")
      return True
    except Exception as e:
      self.logger.error(f"Error actualizando dashboards: {e}")
      return False

  def _paso_notificaciones(self):
    """
    Paso de env√≠o de notificaciones
    """
    try:
      # Verificar si hay alertas cr√≠ticas
      estado_monitoreo = self.sistema.monitorear_sistema()
      alertas_criticas = [a for a in estado_monitoreo['alertas_activas']
      if a['severidad'] == 'Alta']
      if alertas_criticas:
        self._enviar_alertas_criticas(alertas_criticas)
      # Enviar resumen diario
      self._enviar_resumen_diario(estado_monitoreo)
      return True
    except Exception as e:
      self.logger.error(f"Error enviando notificaciones: {e}")
      return False

  def _paso_monitoreo(self):
    """
    Paso de monitoreo final del sistema
    """
    estado = self.sistema.monitorear_sistema()
    # Guardar estado de monitoreo
    archivo_monitoreo = f"monitoreo_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(archivo_monitoreo, 'w') as f:
      # Convertir datetime a string para JSON
      estado_json = estado.copy()
      estado_json['timestamp'] = estado_json['timestamp'].isoformat()
      if 'fecha_entrenamiento' in estado_json['metricas_actuales']:
        estado_json['metricas_actuales']['fecha_entrenamiento'] = \
        estado_json['metricas_actuales']['fecha_entrenamiento'].isoformat()
      json.dump(estado_json, f, indent=2)
    self.logger.info(f"Estadode monitoreo guardado en: {archivo_monitoreo}")
    return True

  def _enviar_alertas_criticas(self, alertas):
    """
    Env√≠a alertas cr√≠ticas por email (simulado)
    """
    self.logger.warning(f"üö®ENVIANDO {len(alertas)} ALERTAS CR√çTICAS")
    for alerta in alertas:
      self.logger.warning(f"-{alerta['tipo']}: {alerta['mensaje']}")
    # En producci√≥n real, aqu√≠ se enviar√≠an emails
    return True

  def _enviar_resumen_diario(self, estado):
    """
    Env√≠a resumen diario del sistema (simulado)
    """
    self.logger.info("üìßEnviando resumen diario del sistema")
    resumen = f"""
RESUMEN DIARIO
-
SISTEMA ML RETAILMAX
====================================
Estado General: {estado['estado_general']}
Timestamp: {estado['timestamp']}
M√©tricas del Modelo:
-
R¬≤: {estado['metricas_actuales'].get('r2', 'N/A')}
-
MAE: {estado['metricas_actuales'].get('mae', 'N/A')}
-
MAPE: {estado['metricas_actuales'].get('mape', 'N/A')}%
Alertas Activas: {len(estado['alertas_activas'])}
Sistema funcionando correctamente.
"""
    self.logger.info("Resumen diario enviado")
    return True

  def _generar_reporte_ejecucion(self):
    """
    Genera reporte detallado de la ejecuci√≥n
    """
    archivo_reporte = f"reporte_ejecucion_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(archivo_reporte, 'w') as f:
      # Convertir timestamps a strings
      resultados_json = {}
      for paso, resultado in self.resultados_ejecucion.items():
        resultado_json = resultado.copy()
        if 'timestamp' in resultado_json:
          resultado_json['timestamp'] = resultado_json['timestamp'].isoformat()
        resultados_json[paso] = resultado_json
      json.dump({
      'sistema_config': SISTEMA_CONFIG,
      'resultados_pasos': resultados_json,
      'resumen': {
      'total_pasos': len(self.resultados_ejecucion),
      'pasos_exitosos': sum(1 for r in self.resultados_ejecucion.values() if r.get('exito', False)),
      'duracion_total': sum(r.get('duracion_segundos', 0) for r in self.resultados_ejecucion.values()),
      'timestamp_reporte': datetime.now().isoformat()
      }
      }, f, indent=2)
    self.logger.info(f"Reporte de ejecuci√≥n guardado en: {archivo_reporte}")

# Crear orquestador y ejecutar flujo completo
orquestador = OrquestadorProduccion(sistema_ml)

"""#### Paso 4: Ejecuci√≥n del Sistema Completo

"""

import json

report_file = 'reporte_ejecucion_20260109_022245.json'

try:
    with open(report_file, 'r') as f:
        report_data = json.load(f)

    print(f"Contenido del reporte de ejecuci√≥n '{report_file}':\n")

    # Display overall summary
    print("### Resumen General ###")
    for key, value in report_data['resumen'].items():
        print(f"- {key}: {value}")

    print("\n### Resultados Detallados de los Pasos ###")
    failed_steps = []
    for step_name, step_result in report_data['resultados_pasos'].items():
        if not step_result.get('exito'):
            failed_steps.append((step_name, step_result))
        print(f"- {step_name}: √âxito={step_result.get('exito')}, Duraci√≥n={step_result.get('duracion_segundos', 'N/A')}s, Error={step_result.get('error', 'N/A')}")

    if failed_steps:
        print("\n### Pasos Fallidos Encontrados ###")
        for step_name, step_result in failed_steps:
            print(f"Paso: {step_name}")
            print(f"Error: {step_result.get('error', 'No se proporcion√≥ un error espec√≠fico')}")
            print("---")
    else:
        print("No se encontraron pasos fallidos en el reporte.")

except FileNotFoundError:
    print(f"Error: El archivo '{report_file}' no fue encontrado. Por favor, verifica la ruta y el nombre del archivo.")
except json.JSONDecodeError:
    print(f"Error: El archivo '{report_file}' no es un JSON v√°lido.")
except Exception as e:
    print(f"Ocurri√≥ un error inesperado al leer el archivo: {e}")

def ejecutar_sistema_produccion():
    """
    Funci√≥n principal que ejecuta todo el sistema
    """
    logger.info("üéØINICIANDO SISTEMA COMPLETO DE PRODUCCI√ìN")
    try:
        # Ejecutar flujo completo
        resultados = orquestador.ejecutar_flujo_completo()
        # Analizar resultados
        pasos_exitosos = sum(1 for r in resultados.values() if r.get('exito', False))
        total_pasos = len(resultados)
        duracion_total = sum(r.get('duracion_segundos', 0) for r in resultados.values())
        logger.info("="*60)
        logger.info("RESUMEN DE EJECUCI√ìN")
        logger.info(f"Pasoscompletados exitosamente: {pasos_exitosos}/{total_pasos}")
        logger.info(f"Duraci√≥n total: {duracion_total:.1f} segundos")
        logger.info(f"Tasa de √©xito: {(pasos_exitosos/total_pasos)*100:.1f}%")
        if pasos_exitosos == total_pasos:
            logger.info("üéâSISTEMA EJECUTADO EXITOSAMENTE")
            return True
        else:
            logger.warning("‚ö†Ô∏èSISTEMA EJECUTADO CON ERRORES")
            return False
    except Exception as e:
        logger.error(f"üí•ERROR CR√çTICO EN SISTEMA: {e}")
        return False
# Ejecutar sistema completo
exito_sistema = ejecutar_sistema_produccion()

"""#### Paso 5: Dashboard de Monitoreo del Sistema

"""

def crear_dashboard_monitoreo():
    """
    Crea un dashboard de monitoreo del sistema completo
    """
    # Leer datos de monitoreo
    import glob
    archivos_monitoreo = glob.glob("monitoreo_*.json")
    if not archivos_monitoreo:
        logger.warning("No se encontraron archivos de monitoreo")
        return
    # Leer el archivo m√°s reciente
    archivo_reciente = max(archivos_monitoreo)
    with open(archivo_reciente, 'r') as f:
        datos_monitoreo = json.load(f)
    # Crear visualizaciones de monitoreo
    fig_metricas = go.Figure()
    # M√©tricas del modelo
    metricas = datos_monitoreo['metricas_actuales']
    fig_metricas.add_trace(go.Indicator(
        mode = "gauge+number",
        value = metricas.get('r2', 0) * 100,
        domain = {'x': [0, 0.5], 'y': [0.5, 1]},
        title = {'text': "R¬≤ Score (%)"},
        gauge = {
            'axis': {'range': [None, 100]},
            'bar': {'color': "darkblue"},
            'steps': [
                {'range': [0, 70], 'color': "lightgray"},
                {'range': [70, 85], 'color': "yellow"},
                {'range': [85, 100], 'color': "green"}],
            'threshold': {
                'line': {
                'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': 85
            }
        }
    ))
    fig_metricas.add_trace(go.Indicator(
        mode = "gauge+number",
        value = metricas.get('mae', 0),
        domain = {'x': [0.5, 1], 'y': [0.5, 1]},
        title = {'text': "MAE ($)"},
        gauge = {
            'axis': {'range': [0, 3000]},
            'bar': {'color': "darkred"},
            'steps': [
                {'range': [0, 1000], 'color': "green"},
                {'range': [1000, 2000], 'color': "yellow"},
                {'range': [2000, 3000], 'color': "lightgray"}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': 2000
            }
        }
    ))
    # Estado del sistema
    fig_metricas.add_trace(go.Indicator(
        mode = "number+delta",
        value = len(datos_monitoreo['alertas_activas']),
        domain = {'x': [0.25, 0.75], 'y': [0, 0.5]},
        title = {'text': "Alertas Activas"},
        delta = {'reference': 0, 'position': "top"}
    ))
    fig_metricas.update_layout(
        title="Dashboard de Monitoreo-Sistema ML RetailMax",
        height=600
    )
    # Guardar dashboard
    fig_metricas.write_html("dashboard_monitoreo_sistema.html")
    logger.info("Dashboard de monitoreo guardado en: dashboard_monitoreo_sistema.html")
    return fig_metricas
# Crear dashboard de monitoreo
dashboard_monitoreo = crear_dashboard_monitoreo()

"""#### Paso 6: Sistema de Backup y Recuperaci√≥n

"""

import glob # Importar el m√≥dulo glob
def crear_sistema_backup():
    """
    Crea sistema de backup para todos los componentes
    """
    logger.info("üíæCreando backup del sistema...")
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    carpeta_backup = f"backup_sistema_{timestamp}"
    import os
    import shutil
    # Crear carpeta de backup
    os.makedirs(carpeta_backup, exist_ok=True)
    # Archivos a respaldar
    archivos_backup = [
    'sistema_ml_production_*.log',
    'predicciones_batch_*.csv',
    'reporte_*.html',
    'monitoreo_*.json',
    'reporte_ejecucion_*.json',
    'dashboard_monitoreo_sistema.html']
    archivos_respaldados = []
    for patron in archivos_backup:
        archivos = glob.glob(patron)
        for archivo in archivos:
            try:
                shutil.copy2(archivo, carpeta_backup)
                archivos_respaldados.append(archivo)
            except Exception as e:
                logger.warning(f"No se pudo respaldar {archivo}: {e}")
    # Crear manifiesto del backup
    manifiesto = {
    'timestamp_backup': timestamp,
    'version_sistema': SISTEMA_CONFIG['version'],
    'archivos_respaldados': archivos_respaldados,
    'total_archivos': len(archivos_respaldados),
    'estado_sistema': sistema_ml.estado_sistema
    }
    with open(f"{carpeta_backup}/manifiesto_backup.json", 'w') as f:
        json.dump(manifiesto, f, indent=2)
    logger.info(f"‚úÖBackup completado: {len(archivos_respaldados)} archivos en {carpeta_backup}")
    return carpeta_backup
# Crear backup del sistema
carpeta_backup = crear_sistema_backup()

"""#### Paso 7: Documentaci√≥n Final del Sistema

"""

def generar_documentacion_final():
    """
    Genera documentaci√≥n completa del sistema implementado
    """
    documentacion = f"""
# SISTEMA ML RETAILMAX-DOCUMENTACI√ìN DE PRODUCCI√ìN

## Informaci√≥n General
-**Versi√≥n:** {SISTEMA_CONFIG['version']}
-**Fecha de Deployment:** {SISTEMA_CONFIG['fecha_deployment']}
-**Ambiente:** {SISTEMA_CONFIG['ambiente']}
-**Estado Actual:** {sistema_ml.estado_sistema}
## Arquitectura del Sistema

### Componentes Implementados
{chr(10).join([f"-{k}: {'‚úÖActivo' if v else '‚ùåInactivo'}" for k, v in SISTEMA_CONFIG['componentes'].items()])}

### Flujo de Datos

1. **Ingesta de Datos:** Carga autom√°tica desde fuentes configuradas
2. **Preprocesamiento:** Limpieza y transformaci√≥n de datos
3. **Entrenamiento:** Modelo RandomForest con validaci√≥n temporal
4. **Validaci√≥n:** Verificaci√≥n de m√©tricas contra thresholds
5. **Predicci√≥n:** Generaci√≥n de predicciones batch
6. **Reportes:** Generaci√≥n autom√°tica de reportes HTML/PDF
7. **Dashboards:** Actualizaci√≥n de interfaces de usuario
8. **Monitoreo:** Verificaci√≥n continua de performance
9. **Alertas:** Notificaciones autom√°ticas por email
## M√©tricas de Performance Actuales
-**R¬≤ Score:** {sistema_ml.metricas_actuales.get('r2', 'N/A')}
-**MAE:** ${sistema_ml.metricas_actuales.get('mae', 'N/A')}
-**MAPE:** {sistema_ml.metricas_actuales.get('mape', 'N/A')}
-**Accuracy ¬±10%:** {sistema_ml.metricas_actuales.get('accuracy_10pct', 'N/A')}

## Thresholds de Calidad
-**R¬≤ M√≠nimo:** {SISTEMA_CONFIG['thresholds']['r2_minimo']}
-**MAE M√°ximo:** ${SISTEMA_CONFIG['thresholds']['mae_maxima']}
-**Confianza M√≠nima:** {SISTEMA_CONFIG['thresholds']['confianza_minima']}

## Archivos Generados
-**Logs del Sistema:** `sistema_ml_production_YYYYMMDD.log`
-**Predicciones:** `predicciones_batch_YYYYMMDD_HHMMSS.csv`
-**Reportes:** `reporte_*_YYYYMMDD.html/pdf/xlsx`
-**Monitoreo:** `monitoreo_YYYYMMDD_HHMMSS.json`
-**Dashboard:** `dashboard_monitoreo_sistema.html`
## Interfaces de Usuario
### 1. Dashboard Streamlit
-**URL:** [Configurar despu√©s del deployment]
-**Usuarios:** Gerentes de tienda, analistas
-**Funcionalidad:** Predicciones interactivas, an√°lisis de escenarios

### 2. Dashboard Ejecutivo (Google Data Studio)
-**URL:** [Configurar despu√©s del deployment]
-**Usuarios:** Ejecutivos, directores
-**Funcionalidad:** KPIs, alertas, tendencias

### 3. Dashboard de Monitoreo
-**Archivo:** `dashboard_monitoreo_sistema.html`
-**Usuarios:** Equipo t√©cnico
-**Funcionalidad:** Estado del sistema, m√©tricas t√©cnicas

## Procedimientos Operacionales

### Ejecuci√≥n Manual:

Ejecutar sistema completo
---
python sistema_ml_retailmax.py
---
### Ejecuci√≥n Programada
-**Frecuencia:** Semanal (lunes 8:00 AM)
-**M√©todo:** Google Apps Script + Colab
-**Backup:** Autom√°tico despu√©s de cada ejecuci√≥n

### Monitoreo
-**Logs:** Revisi√≥n diaria de archivos de log
-**Alertas:** Configuradas para m√©tricas cr√≠ticas
-**Dashboard:** Actualizaci√≥n en tiempo real

### Mantenimiento
-**Reentrenamiento:** Autom√°tico si performance < threshold
-**Backup:** Semanal de todos los componentes
-**Auditor√≠a:** Mensual de calidad de datos y modelo

## Contactos y Escalaci√≥n
-**Equipo Data Science:** data-team@retailmax.com
-**Soporte T√©cnico:** tech-support@retailmax.com
-**Escalaci√≥n Cr√≠tica:** cto@retailmax.com

## Pr√≥ximos Pasos
1. Configurar ejecuci√≥n programada en producci√≥n
2. Implementar monitoreo avanzado con alertas
3. Optimizar performance del modelo
4. Expandir a m√°s tiendas y regiones
5. Implementar A/B testing para nuevas versiones

---
**Documentaci√≥n generada autom√°ticamente el {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}**
"""
    # Guardar documentaci√≥n
    with open('DOCUMENTACION_SISTEMA_ML.md', 'w', encoding='utf-8') as f:
        f.write(documentacion)
    logger.info("üìöDocumentaci√≥n final generada: DOCUMENTACION_SISTEMA_ML.md")
    return documentacion
# Generar documentaci√≥n final
doc_final = generar_documentacion_final()
